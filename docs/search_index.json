[["index.html", "Introduction to Data Analysis with R and the Tidyverse Welcome! Why R? Course Organization About the Author", " Introduction to Data Analysis with R and the Tidyverse Allan Quadros, Ph.D. October 2025 | Revision February 2026 Welcome! This is the repository for the textbook of the Introduction to Data Analysis in R using Tidyverse course. To reproduce the code present in the book, you need a recent version of R and updated packages. At the beginning of each section, you will be introduced to the packages needed to execute the code related to that topic. It is highly recommended to use the most recent version of the Integrated Development Environment (IDE) RStudio. Bugs and typos found in this book can be reported in the its Git repository: https://github.com/allanvc/book_IDART_en/issues/ Why R? The R programming language is known for having a relatively slow learning curve, but once students understand the basic structure of objects that make up the language, learning becomes exponential. Figure 0.1: R Learning Curve R is relatively different from other programming languages because it was developed by Statisticians for Statisticians. It wasn’t designed to be the most efficient language in terms of speed, but rather to make the lives of those who analyze data easier. My experience with other programming languages leads me to affirm that this is true: there is no language more suitable for data analysis than R. Individual preferences and other conveniences may lead to choosing one language or another, but there’s no denying the fact that R has the best tools for Data Wrangling (data preparation), graph generation, report generation, and reproducibility. Furthermore, R is globally recognized for its extremely active and inclusive community. It is the preferred language in academia, given that new mathematical, statistical, and/or computational techniques are implemented first in R. It is also one of the most used languages in industry for Data Science, along with Python. For these reasons and for being an open source language, endowed with a powerful package management environment, the dissemination of R use in its 20 years of history has been extremely rapid and has relegated data analysis environments and languages like SAS, SPSS, and Stata to second place. In R, you’ll find packages for the most diverse purposes: from packages that generate exams from a question bank, through data preparation packages, mathematical optimization, Machine Learning, to packages for audio analysis, application creation, reading and sending emails. Today, there are several environments and languages used for Data Analysis, such as Python, Julia, Scala, SAS, etc. However, none of them provide the combination of an excellent package management ecosystem, statistical capabilities, visualization options, and a powerful IDE (Integrated Development Environment) - all implemented by the R community. For all these characteristics, the benefits of learning the R language are truly considerable. Course Organization This course is divided into 4 Modules. Module 1 seeks to familiarize students with the basic concepts of the language, covering history, basic functionalities, and the structure of the most important objects in R. Modules 2 and 3 are always divided into 3 parts: data reading, data manipulation, and visualization. With each Module, new packages are presented for these functionalities, with a slightly deeper level of specialization compared to the previous module. Module 4 begins with a focus on string manipulation and regular expressions (REGEX) and ends by presenting report production techniques and reproducibility in R. About the Author Allan Quadros is an Instructor of Information Systems and Operations Management at the University of North Florida (UNF), where he teaches data and business analytics in the Coggin College of Business. He earned a Ph.D. in Statistics from Kansas State University (2025), an M.Sc. in Economic Development from the State University of Campinas (UNICAMP, 2012), and a B.Sc. in Statistics from the University of Brasília (UnB, 2018). Allan is the author of several R packages, including emstreeR, mRpostman—recognized by RStudio’s R Views Blog as one of the top 40 new CRAN packages in August 2019—and onlineretail. His work spans computational statistics, Bayesian statistics, financial econometrics, and data-driven applications in business and finance. Among his professional experience, selected highlights include serving as Lead Data Scientist at Brazil’s National Fund for Educational Development (FNDE) and developing an equipment-failure risk model for the USDA’s National Bio and Agro-Defense Facility (NBAF). He has published peer-reviewed research and presented at international conferences. His teaching has been recognized with multiple honors, including the William L. Stamey Award for Excellence in Teaching (Kansas State University College of Arts and Sciences, 2023), the Graduate Student Council Award for Graduate Student Teaching Excellence (2024), and a nomination for the Midwestern Association of Graduate Schools’ Excellence in Teaching Award (2025). More information can be found at: https://allanvc.github.io Contact Information: - Email: allan.quadros[at]unf.edu - Office: Coggin College of Business, Building 42, Office 1110 - University of North Florida, 1 UNF Drive, Jacksonville, FL 32224 "],["m1.html", " 1 Module I 1.1 First Steps 1.2 R Language Object Structure", " 1 Module I 1.1 First Steps 1.1.1 Brief History R is a language and environment for statistical programming that runs on various *NIX platforms, Windows and MacOS (R-project.org), and can be downloaded and distributed freely according to the General Public License (GPL). The origin of the name R goes back to the S language, developed by John Chambers between 1975 and 76 at Bell Labs (former AT&amp;T and current Lucent Technologies) – the same place where important innovations in computing originated, such as the UNIX operating system, the C programming language, transistors, among others. In contrast to the commercial implementation of the S language – S-PLUS, Ross Ihaka and Robert Gentleman, professors from the Department of Statistics at Auckland - New Zealand, created R as a free and open-source alternative to the S language, in 1995. The name R itself comes from a play on the S language and the initials of the authors’ names, Ross and Robert. Figure 1.1: Birthplace of R indicated with the leaflet package. Click on the blue pin 1.1.2 Installing R Installing the R environment is easy to do on any operating system. On Windows, the steps are: 1 Access the website https://www.r-project.org/. 2 Click on download R or CRAN mirror. 3 Choose the repository (Comprehensive R Archive Network - CRAN) of your preference. 4 Click on Download R for Windows. 5 Click on base. 6 Download the installation executable by clicking on Download R X.X.X for Windows. 7 Run the downloaded file to install the software. The default R window on Windows is quite simple. You can see it’s divided into a larger window, called R GUI (R Graphical User Interface); and an R Console window. In this last window, when starting R, there’s a description about the version used and some tips about the language. The &gt; sign indicates the command line or prompt, which is where you type the commands to be run by the interpreter. R Graphical Interface on Windows Here, it’s worth making a distinction between the R language and some other programming languages: the R language is an interpreted language, that is, code execution occurs together with code analysis, as if it were on-demand. You type the code, give the execution command and immediately the interpreter gathers the commands, translates them to machine language (or low-level language) and transfers them to the processor for execution. Another example of an interpreted language would be Python. In compiled languages, code analysis occurs in only one phase – compilation – when data is analyzed and source code is transformed into target code. The target code usually stays separate, in an executable file, which will be executed at a later time. 1.1.3 Installing RStudio Considering that R’s original graphical interface is quite modest, there are several Integrated Development Environments (IDEs) that gather various tools to support programming and data analysis, with the goal of making users’ lives easier. The most used IDE for the R language is RStudio. See below steps to install RStudio on Windows: Access the website https://www.rstudio.com/. Click on DOWNLOAD. Choose the FREE version and click on DOWNLOAD RStudio for Windows. As you can see, RStudio’s graphical interface is more “friendly” than R’s default. The window is divided into three parts: one for Console, another for Environment, History and Connections and another for Files, Plots, Packages, Help and Viewer. Other tabs can be added to the Environment, History and Connections panel, depending on the type of work you’re developing in R, such as the Presentations tab when producing slides or the Build tab when building and testing a package. The names in general are self-explanatory, but we’ll talk more about them in the next modules. RStudio Interface 1.1.4 Installing RTools on Windows Later on, we’ll see how to install packages in R, which are nothing more than modules that can be added to your standard R installation. It happens that some of these modules have parts written in other languages, such as C++ and Fortran, which are compiled languages. By default, Windows doesn’t come with compilers that can perform this task, unlike Linux and Mac. To work around this problem on Windows, we install RTools. The Windows RTools application, also developed by the R Foundation, contains compilers and other tools necessary to install R packages that require compilation. Installation is quite simple: Access https://cran.r-project.org/bin/windows/Rtools/ Download the recommended executable, usually marked in green with the observation recommended; Run the application keeping the default options suggested during installation. 1.1.5 Basic Functionalities of R and RStudio 1.1.5.1 R as a Calculator The most basic way to use R is as a calculator. Basic arithmetic operations are performed with the following operators in R: Operator Operation + addition - subtraction * multiplication / division ^ or ** exponentiation x%%y modulo remainder x%/%y integer quotient Let’s see some examples, typing in our console, right next to &gt;, the following operations: 2+1 ## [1] 3 4-2 ## [1] 2 2*3 ## [1] 6 3/3 ## [1] 1 3^2 ## [1] 9 3**2 ## [1] 9 5%%2 ## [1] 1 5%/%2 ## [1] 2 Notice that next to all answers, [1] appeared. The brackets and the number 1 inside indicate that in that line is the first element of the resulting object. This happens because R, whenever possible, works in a vectorized way. The value inside [ ] indicates the position within the answer vector of the number right after it (result). Since in each operation, the answer is unique, all values were located in the first position of our answer vector. This will be very useful when you want, for example, to apply a mathematical operation or any other transformation to all entries in a column in a table and print the result in the console. In the output, R will break the result into some lines and these numbers in brackets will help us identify which position in the answer vector the first number of each line in the output printed in the console belongs to. Try for example: 1:100 * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 ## [28] 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 ## [55] 110 112 114 116 118 120 122 124 126 128 130 132 134 136 138 140 142 144 146 148 150 152 154 156 158 160 162 ## [82] 164 166 168 170 172 174 176 178 180 182 184 186 188 190 192 194 196 198 200 In our example, R chose to break the multiplication of 100 numbers into groups of 17 numbers in the first 4 lines and a group of 15 values in the last. In the first line of our output, 2 is the element at position 1 ([1]) of the answer vector; in the second line, the number 36 is the element that refers to position 18 ([18]) of the answer vector and so on, until the last line that starts at element at position 86. 1.1.5.1.1 Prioritization and Hierarchy of Operations Just like in MS Excel, parentheses will also be very useful for performing both arithmetic operations and comparisons and sequential execution of functions in R. With them, we can indicate the “priority” or order in which calculations/computations should be performed. Try the example below: ((1007+1)/8)^2 ## [1] 15876 Note that the operation is done from the inside out. First the interpreter executes (1007+1), then divides this result by 8 (/8), to only then square everything (^2). Without parentheses, the result would be quite different: 1007+1/8^2 ## [1] 1007.016 1.1.5.2 Logical Operators You can also perform logical comparisons in R. Below are some of the logical operators that will be important in the first modules of the course. Others will be presented in the remaining modules: Operator Operation &gt; greater than &gt;= greater than or equal to &lt; less than &lt;= less than or equal to == equal to != different from x&amp;&amp;y x AND y x||y x OR y Let’s see some examples: 2 &gt; 1 ## [1] TRUE 1009 &gt;= 1009 ## [1] TRUE 3 &lt; 0.7 ## [1] FALSE 3 &lt;= 3.0001 ## [1] TRUE 7 == 5 ## [1] FALSE 4353.789 == 4353.7891 ## [1] FALSE 8 != 13 ## [1] TRUE 4353.789 != 4353.7891 ## [1] TRUE 2 == 2 &amp;&amp; 7 != 5 ## [1] TRUE (2 == 2) &amp;&amp; (7 != 5) ## [1] TRUE (2 == 3) || (7 &lt;= 5) ## [1] FALSE 4353.789 != 4353.7891 || 7 &gt;= 0.7 ## [1] TRUE Note that the answers are, in these examples, always a logical vector: TRUE or FALSE. Later on, we’ll see the other types of vectors existing in R. 1.1.5.3 Saving your code in a script In RStudio, you can add a small panel, which will make your work even easier. This is the source pane, a panel where you can create scripts to store multiple lines of code, so you can execute them all at once or line-by-line. If you want to save the calculations and logical comparisons you did earlier in a file so you can execute them later, you can do it through a script. In the script window, you can keep a trail of all commands used. This is important because it optimizes the use of R by allowing running the same code for different files and different occasions, instead of having to redo all the programming every time our input data changes. You can open several script windows, side by side, and navigate between them, as you do with browser tabs. In this course, we’ll do all classes and exercises using script files. To add the script window (source pane), just create a new file by clicking on , just below File, and then on . Our RStudio window should look like the following figure. Let’s add all the lines of code we executed earlier to our newly created script. TIP: You can insert comments in your scripts as a way to document the steps of your work for future reference. In R, comments are included with the # character. To save the script file, just press Ctrl+S or click on the single diskette in the menu bar. This file will be saved with extension .R, indicating it’s a file with R language code. TIP: We suggest you create and save one or more scripts for each class/section. This will help you organize your material and recover important concepts and examples during and after the course. You can execute all lines of a script or choose to execute only a few lines or specific parts of this code. Select the part you want to execute and press Ctrl+Enter. You’ll see, in the console (window below the script), your code being executed. An alternative to Ctrl+Enter is to select the part or line(s) and click on . Most of the time, our code can take considerable time to be executed completely. To know if the interpreter is still busy executing your code, just look at the right corner of the Console panel. If you see the symbol , the interpreter is still busy executing the last sequence of commands. The \"&gt;\" symbol will also not appear free in the console. You can try to stop execution by clicking on the stop icon. However, it won’t always be possible to interrupt it. Try generating a normal distribution with 100 million entries: rnorm(1:100000000) TIP: It can also happen that you look at the console and don’t see the &gt; symbol, without the stop icon appearing in the right corner of the panel. This usually happens when we forget to close some parenthesis, brace or bracket opened at the beginning of a code line. Do a test: ((1007+1)/8^2 The console will be waiting for you to complete the code. You have two options: add the missing parenthesis (if possible) directly in the console, or press Esc, fix the code and execute it again. 1.1.5.4 Environment Tab All objects that are created in your R/RStudio session will be automatically stored in what we call the Global Environment, represented by the Environment tab in RStudio. Environment Tab Note that so far, our Environment is empty. This is because we haven’t “saved” any objects or results from the operations we performed earlier. 1.1.5.4.1 Object Assignment in R To create an object in R, whether to store a specific value or the result of an operation, we use R’s characteristic assignment sign &lt;-, i.e. a &lt;- b (read a receives the value of b). You can also use the reverse direction: b -&gt; a (a receives the value of b), or even the equals sign =. These alternatives are less conventional. We suggest using a &lt;- b so as not to confuse object creation with passing parameters in function arguments later on. To create an object/variable x that contains the value 2, execute: # x receives 2 x &lt;- 2 # to see the value of x: x ## [1] 2 TIP: The shortcut for the assignment operator &lt;- is Alt+-. Note now that our Environment tab is no longer empty: Now let’s save the results of some arithmetic operations and logical comparisons: out1 &lt;- 789/34.5 out2 &lt;- 3^2 out3 &lt;- out1 &gt; out2 Let’s see how our Environment looks with the new objects created: R is quite liberal regarding its object naming policy. The prohibitions are only the following: a name cannot start with a digit, e.g.: 1out &lt;- 2; a name cannot contain only digits, e.g.: 01 &lt;- 2; a name cannot contain special characters, except . or _, e.g.: out#01 &lt;- 2 a name cannot be identical to a word used as a token of the R language, e.g.: TRUE &lt;- 2; for &lt;- 2, etc. TIP: The R language is case sensitive, that is, it distinguishes between uppercase and lowercase letters in a name. Therefore Object_Name != object_name! 1.1.5.5 Saving Environment objects What if you want to save these objects created in your R session, to continue working on them later? It’s possible to do it and it’s simple. To save all objects from your Environment, click on Session and Save Workspace As... in RStudio. A file with extension .RData will be saved with the name and path you specify. An alternative would also be: save.image(&quot;C:\\\\path_to_preferred_folder\\\\my_workspace.RData&quot;) # or save.image(&quot;C:/path_to_preferred_folder/my_workspace.RData&quot;) TIP: The backslash \\ has a special function in R, it functions as an escape character, which we’ll see more in depth in future sessions. Therefore, for a backslash to stop having its special function, we need to “escape it” with another backslash. That’s why we use two slashes in Windows addresses. One way to work around this is to use forward slashes, as in Linux. Even on Windows, R will know you’re specifying a Windows path. To load the saved file in future sessions, you again have two alternatives. The first is to click on Session and Load Workspace... in RStudio. The second is: load(&quot;C:\\\\path_to_preferred_folder\\\\my_workspace.RData&quot;) If you want to save specific elements and not the entire environment, you can do it as follows: save(out1, out2, file=&quot;C:\\\\path_to_preferred_folder\\\\my_objects.RData&quot;) To load these objects, you can also use the load() function. TIP: To save and load a single element, such as a dataset (table) that was worked on but should still be loaded in a new session, you can use the saveRDS() and readRDS() functions. This is a more optimized format for saving large objects. 1.1.6 R Language Structure R can be considered a functional programming language, since most procedures and routines are performed through functions that receive some arguments as input, perform some actions on these arguments and return an output. Roughly speaking, function usage happens as follows: function_name(argument1 = value1, argument2 = value2, ...) Although the arithmetic and logical operators seen earlier don’t fit the functional structure described above, they end up operating internally as functions. As you’ll see later on, any user can create a function in R and not only use those made available by the language’s default distribution. TIP: We don’t always need to use the argument_name=value format inside functions, because R is smart enough to match arguments by the position they’re passed (function_name(value1, value2)) or even by the initial letters of the informed argument. Let’s see some examples of functions that perform mathematical operations and that come factory-installed in base R (R’s basic distribution): TIP: RStudio has the functionality of autocompleting the words you type with objects created during your R session or already existing in memory. When typing the functions below, test by typing the first two letters of each function and pressing TAB. # square root sqrt(81) ## [1] 9 # combining with operation prioritization sqrt((3*3)^2) ## [1] 9 ## product prod(2,2) # 2x2 ## [1] 4 prod(2,3,5,7,8) # 2x3x5x7x8 ## [1] 1680 ## logarithm # log of 3 in base e log(3) # natural log ## [1] 1.098612 # log of 3 in base 10 log(3,10) ## [1] 0.4771213 # log3 in base 10 log10(3) ## [1] 0.4771213 # abs = modulus, |3 - 9| abs(3-9) ## [1] 6 # factorial # 4 factorial factorial(4) ## [1] 24 1.1.6.1 Packages in R One of the reasons for the great success of the R language is due to the fact that any user can develop a “suite” containing various functions to perform one or several tasks. This set or suite of functions can be made available in the form of a package, which other users can install and also benefit from. After meeting a series of demanding requirements, these packages are usually made available on the Comprehensive R Archive Network (CRAN). CRAN has a quite serious package review policy. For an R package to be part of the CRAN repository, it must meet a series of requirements and be approved in several tests focused essentially on the following factors: user safety; error-free functioning on at least two operating systems; dense documentation (including bibliographic citations) about the package’s functionalities. All this makes packages made available on CRAN quite reliable, thus becoming the official source for package distribution of the language. If you want to know the number of packages available on CRAN today, execute: dim(available.packages(contrib.url(getOption(&quot;repos&quot;)), filters=list()))[1] In March of 2020 there were more than 15 thousand packages available on CRAN for the most diverse purposes. To see types of packages which exist in the repository, a visit to CRAN’s Task Views is recommended. There are packages for Econometrics, Regional Economic Analysis, Statistics, Clustering, Clinical Trials, Time Series, Optimization, Data Processing, Machine Learning and many others. 1.1.6.2 Installing packages To install packages available on CRAN, use the install.packages(\"package_name\") function, passing the desired package name in quotes as a function argument. Let’s test this functionality by installing the ggplot2 package, which is a package you’ll probably use a lot in your analyses: install.packages(&quot;ggplot2&quot;) If the package was correctly installed, you should see something similar to the following message in the console: package &#39;ggplot2&#39; successfully unpacked and MD5 sums checked The downloaded binary packages are in C:\\Users\\...\\...\\...\\...\\...\\downloaded_packages &gt; Don’t be alarmed if other packages were also installed. This is very common, since some packages may resort to functions present in other libraries. To load or attach the package to your R session, so you can use the functions available in it, we use the library(package_name) or require(package_name) function. In this case, the package name can come with or without quotes. library(ggplot2) If you don’t want to load a package completely in your R session, because you’ll only use a specific function, instead of library(), you can use the format package_name::function_name(parameter). 1.1.6.3 Other package sources It’s worth noting that the basic installed version of R, which we call base R, already comes with some packages installed, such as the stats, MASS, foreign, graphics, base itself, among others. To list all packages installed on your machine, execute: installed.packages() Although CRAN is the official R package repository, it’s important to mention the existence of other important sources for obtaining packages as well. The first of alternative sources is Bioconductor, which is an open source software development project related to analysis and understanding of genomic data generated in laboratory experiments related to molecular biology. It’s therefore an important package repository for those working with Bioinformatics or Biostatistics. The second source would be Github which is a system for code management and versioning. Anyone can create a github account and start sharing their code, which can be accessed and modified/improved (with the original author’s consent). In R’s case, packages usually have a stable version on CRAN and a development version on Github, where authors and other collaborators are working on improving and resolving package bugs. Once the GitHub version is stable and ready for release, the author can send it to CRAN. Access the repository of the emstreeR package on Github: https://www.github.com/allanvc/emstreeR. You can install R packages from their versions on Github. This is relatively common and occurs when a new functionality you want to test was implemented only in the package’s development version and isn’t yet available on CRAN. To install packages from their versions on Github, you need another package first, devtools. Let’s install the development version of the emstreeR package: install.packages(&quot;devtools&quot;) # if you don&#39;t have it installed on your machine # alternative 1 devtools::install_github(repo=&quot;allanvc/emstreeR&quot;) # or # alternative 2 library(devtools) install_github(repo=&quot;allanvc/emstreeR&quot;) Note that we passed the repository path in the repo argument. 1.1.7 How to get help This is perhaps the most important part of all the material. Knowing how and where to seek help can mean spending just a few minutes instead of hours or even days solving a problem involving data analysis and programming. Throughout this course and when using R in a work activity, you’ll encounter various questions involving programming logic, data analysis, or even trying to know if there’s already an implemented package that performs the task you need. 1.1.7.1 R’s Help The first place to seek help about something related to R is usually within R or RStudio itself. As we mentioned in section @ref(#pkg), CRAN’s policy requires packages to be very well documented. And this helps users and developers a lot. In addition to base R documentation and other packages that already accompany the standard installation, when installing a new package, this new library’s documentation becomes part of R’s help installed on your machine. So, when we want to understand a function, that is, know its input parameters, what it does and what it returns, it’s recommended to use R’s own help. In the lower right panel, you’ll find a series of tabs, the 3rd of which is the tab that displays help material. You can do searches using the search field in the tab itself, or through commands inserted in the console. R/Rstudio help panel An example: imagine you’d like to know if R has any function that calculates the logarithm (base \\(e\\)) of a number. For this, we have the help.search() function, which receives as a parameter (“in quotes”) the topic you want to search about. All R help is in English; therefore, if you want to find something related to logarithm, you should execute the help.search(\"logarithm\") or ??logarithm command. Let’s see: # alternative 1 help.search(&quot;logarithm&quot;) # or # alternative 2 ??logarithm In RStudio’s Help tab the results of packages and respective functions containing the words you searched for will appear. In this case, therefore, we have the log() function from the base package to calculate logarithms. See: Search results If you already know exactly the name of the R function or object you want to get help about, you can also use help(\"word\") or ?word. # alternative 1 help(&quot;log&quot;) # or # alternative 2 ?log log() function documentation Generally, the most important topics in help files are Description, Usage, Arguments and Examples. The first shows what the function does, the second how the function should be used, the third what arguments it receives and, in the fourth, you find examples of how it works. Value can also be interesting, as it informs what type of object the function returns. 1.1.7.1.1 Vignettes Later on, we’ll see how to install new packages in R. These packages are like additional modules that allow the user to perform more operations and activities in the language. Many of these packages bring with them, in addition to basic documentation, true tutorials on how to use the package itself or specific functions of these packages. They’re much more detailed than the simple Help documentation of the package or a function. While some don’t provide any vignette, others can bring more than one vignette. If you want to check, use: vignette(&quot;package_name&quot;) 1.1.7.2 Help via Internet R is well known for its extremely active community. Often, when analyzing data, problems arise that cannot be solved only with the language’s internal documentation. In these cases, it’s necessary to resort to the experience of other users who have experienced the problem and can give tips on how to reach the desired point. In R’s 20 years, it will be difficult not to find someone who experienced the same problem as you. At this point the internet is our best friend and it’s no shame to look for help there. From the most inexperienced language users to the most talented R developers, everyone, without exception, ends up resorting to the internet as a valuable source of information and help. There are free books, blogs with excellent tutorials, forums and Q&amp;A (questions and answers) sites. In the latter case, there’s no way not to mention StackOverflow, which is a questions and answers website specialized in programming in general. The R community on StackOverflow is extremely active and one of the largest on the site. There you’ll find beginner, intermediate, advanced users, package developers and even people who work on updating the language and RStudio. There’s a Portuguese version and an English one. Resort to the English version of the site, as it’s obviously much more active. Before posting a question there, do a search with the terms you want, for example: “How do I make a scatter plot in R?”. If you type this in the site’s search or even on Google, in the first results you’ll already have the necessary answers from StackOverflow to make a scatterplot in R, in at least 3 different ways, using different packages. See an example of a question and answer on StackOverflow: Question Answer 1.2 R Language Object Structure Understanding the structure of creating and manipulating objects in R will be essential to boost your learning speed in the remaining course sessions. Good use of more practical topics depends a lot on a solid understanding of R language objects. Everything (or almost everything) in R is objects. The most important are: Vectors: are a kind of one-dimensional array. They consist of a sequence of values that can be: numeric, characters or logical expressions (like TRUE or FALSE). It’s emphasized that vector entries can be of only one single type. Example: ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 Matrices: are multidimensional arrays with a collection of vectors in rows or columns, with all vectors in the collection having the same type and size. Example: ## [,1] [,2] ## [1,] &quot;R&quot; &quot;UNF&quot; ## [2,] &quot;UNF&quot; &quot;R&quot; ## [3,] &quot;R&quot; &quot;UNF&quot; ## [4,] &quot;UNF&quot; &quot;R&quot; ## [5,] &quot;R&quot; &quot;UNF&quot; Dataframes: in terms of appearance, they’re practically identical to matrices, but with the possibility of having a collection of vectors (columns) of different types (e.g.: a numeric vector and another character vector). Because of this characteristic, it’s the main object used to store data tables in R. Example: ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa Lists: is the broadest type of object, which can gather collections of dataframes, vectors and/or matrices, or even all of them. A list characteristic is that, since objects inside it don’t need to be of the same type, there’s also no need for them to be of the same size. This is often very helpful in data manipulation. Example: ## [[1]] ## [1] &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; ## ## [[2]] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## ## [[3]] ## [,1] [,2] ## [1,] 0.7180336 0.7081718 ## [2,] 0.0601190 0.6106308 Functions: are a set of procedures that receive zero, one or more parameters as input, perform a calculation or procedure and return a result to the user. As you can see, even functions are considered objects in R. Example: ## function (x, base = exp(1)) .Primitive(&quot;log&quot;) In this section, we’ll study more in depth the creation and manipulation of vectors and Dataframes, which we judge to be the most important objects for this course. Function creation will be the object of study in a future module. 1.2.1 Vectors 1.2.1.1 How to create a vector In R there are 3 types of vectors: numeric (numeric), character or strings (character) and logical vectors (logic). They’re all created through the c() function, the “c” standing for concatenate. This function concatenates elements of the same type, thus producing a vector. The parameters to be passed are the elements that will compose the vector and must be separated by commas. Numeric vector: v1 &lt;- c(1, 0.2, 0.3, 2, 2.8); v1 ## [1] 1.0 0.2 0.3 2.0 2.8 TIP: When using ;, you indicate to R that you’re separating code execution, although there are two operations on the same line - one that creates the vector and another that prints the result in the console by calling the object name. TIP: Numeric vectors can be of two types: integer, for integers or double, for floating point (decimal numbers). To know a vector’s type, use the typeof(vector_name) function Character or strings vector: v2 &lt;- c(&quot;R&quot;, &quot;UNF&quot;, &quot;2020&quot;, &quot;R&quot;, &quot;UNF&quot;, &quot;2020&quot;); v2 ## [1] &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; TIP: Note that strings must be passed \"in quotes\". Logical vector: v3 &lt;- c(TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE); v3 ## [1] TRUE FALSE FALSE TRUE TRUE FALSE FALSE TRUE Try mixing two vectors. Since vectors can only be of one single type, R will automatically force the final result to a single type. Example: v4 &lt;- c(v1, v2); v4 ## [1] &quot;1&quot; &quot;0.2&quot; &quot;0.3&quot; &quot;2&quot; &quot;2.8&quot; &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; v5 &lt;- c(v1, v3); v5 ## [1] 1.0 0.2 0.3 2.0 2.8 1.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 v6 &lt;- c(v2, v3); v6 ## [1] &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; &quot;R&quot; &quot;UNF&quot; &quot;2020&quot; &quot;TRUE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;TRUE&quot; &quot;TRUE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;TRUE&quot; seq(-1, -10) ## [1] -1 -2 -3 -4 -5 -6 -7 -8 -9 -10 The typeof(vector_name) function can be used to confirm the types of vectors you created. 1.2.1.1.1 Other ways to create a vector There are other interesting functions that make it possible to create vectors: :, example: 1:100, creates a numeric vector composed of the sequence from 1 to 100; seq(), example: seq(-10, -1), creates a numeric vector composed of the sequence from -10 to -1; rep(), example: rep(\"UNF\", 10), creates a vector composed of the string \"UNF\" repeated 10 times. 1.2.1.2 How to extract elements from a vector To extract elements from a vector (and from any object in R), we use indexing through brackets vector_name[position]. You can inform a single position, a set of positions or even a range of positions to extract: Extracting a single element: # 3rd element of vector v1 v1[3] ## [1] 0.3 # 1st element of vector v2 v2[1] ## [1] &quot;R&quot; # 5th element of vector v3 v3[5] ## [1] TRUE Extracting more than one element: Here you’ll use a vector inside another vector. The idea is that the vector inside the brackets [] contains the positions (indices) to be extracted from the original vector. Remember that the vector containing the positions must be created and, to create a vector, we use the c() function. # 1st and 3rd elements of vector v1 v1[c(1,3)] ## [1] 1.0 0.3 # or pos1 &lt;- c(1,3) v1[pos1] ## [1] 1.0 0.3 # 2nd and 4th element of vector v2 v2[c(2,4)] ## [1] &quot;UNF&quot; &quot;R&quot; # or pos2 &lt;- c(1,3) v2[pos2] ## [1] &quot;R&quot; &quot;2020&quot; # 1st, 2nd and 5th element of vector v3 v3[c(1,2,5)] ## [1] TRUE FALSE TRUE # or pos3 &lt;- c(1,2,5) v3[pos3] ## [1] TRUE FALSE TRUE Extracting elements in a range: Once again we’ll use vector inside vector. The difference is that we’ll create a vector using the : function, which creates a sequence of values or range. We can also use the seq(a,b) function # from 1st to 3rd elements of vector v1 v1[1:3] ## [1] 1.0 0.2 0.3 # or v1[seq(1,3)] ## [1] 1.0 0.2 0.3 # from 2nd to 5th element of vector v2 v2[2:5] ## [1] &quot;UNF&quot; &quot;2020&quot; &quot;R&quot; &quot;UNF&quot; # or v2[seq(2,5)] ## [1] &quot;UNF&quot; &quot;2020&quot; &quot;R&quot; &quot;UNF&quot; # from 3rd to 6th element of vector v3 v3[2:6] ## [1] FALSE FALSE TRUE TRUE FALSE # or v3[seq(2,6)] ## [1] FALSE FALSE TRUE TRUE FALSE 1.2.1.3 How to calculate a vector’s size? TIP: To calculate a vector’s size, use the length(vector_name) function: length(v6) ## [1] 14 1.2.1.4 How to modify vector elements Once you understood the vector indexing process. You can modify or replace one or more elements of a vector, using indexing and assignment. v1[2] &lt;- 450.78 v2[3] &lt;- 2021 v3[c(3,5)] &lt;- c(TRUE, FALSE) # the replacement must be the same size as the indexing result 1.2.2 Dataframes Dataframes are R’s “tables”. They are likely one of the objects you’ll use most to do data analysis. The Dataframe is a bidimentional object with rows and columns, in which the columns work like vectors, where each of these vector positions indicates a row. We can think of Dataframes, then, as a collection of vectors (columns), which can even be of different types, but necessarily must have the same size (number of rows). 1.2.2.1 How to create a Dataframe To create a dataframe, we use the data.frame() function. However, the most common is for the dataframe to be created from reading some database, through reading functions that will be presented mainly in Module 2. Let’s create a dataframe with 3 columns. The main arguments are the vectors that compose the columns. # NOTE: all vectors need to have the same size v6 &lt;- 11:15 v7 &lt;- seq(0.3, 0.7, by=0.1) v8 &lt;- rep(&quot;UNF&quot;, 5) v9 &lt;- rep(c(TRUE, FALSE), 5) df1 &lt;- data.frame(v6, v7, v8, v9) df1 ## v6 v7 v8 v9 ## 1 11 0.3 UNF TRUE ## 2 12 0.4 UNF FALSE ## 3 13 0.5 UNF TRUE ## 4 14 0.6 UNF FALSE ## 5 15 0.7 UNF TRUE ## 6 11 0.3 UNF FALSE ## 7 12 0.4 UNF TRUE ## 8 13 0.5 UNF FALSE ## 9 14 0.6 UNF TRUE ## 10 15 0.7 UNF FALSE TIP: There are several other arguments that can also be used. Let’s see the structure of the data.frame() function. It’s worth consulting the help of the data.frame function too (help(data.frame)). data.frame help(&quot;data.frame&quot;) During dataframe creation, we can choose other names for the columns: df1 &lt;- data.frame(col1 = v6, col2 = v7, col3 = v8, col4 = v9) # or # df1 &lt;- data.frame(&quot;col1&quot; = v6, &quot;col2&quot; = v7, &quot;col3&quot; = v8, &quot;col4&quot; = v9) df1 ## col1 col2 col3 col4 ## 1 11 0.3 UNF TRUE ## 2 12 0.4 UNF FALSE ## 3 13 0.5 UNF TRUE ## 4 14 0.6 UNF FALSE ## 5 15 0.7 UNF TRUE ## 6 11 0.3 UNF FALSE ## 7 12 0.4 UNF TRUE ## 8 13 0.5 UNF FALSE ## 9 14 0.6 UNF TRUE ## 10 15 0.7 UNF FALSE You must have noticed there’s always a column on the left that contains the numbering or names of your dataframe’s rows. This is what we call rownames. TIP: If you want to confirm your dataframe’s structure, that is, know the type of its columns, use the str(dataframe_name) function str(df1) ## &#39;data.frame&#39;: 10 obs. of 4 variables: ## $ col1: int 11 12 13 14 15 11 12 13 14 15 ## $ col2: num 0.3 0.4 0.5 0.6 0.7 0.3 0.4 0.5 0.6 0.7 ## $ col3: chr &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; ... ## $ col4: logi TRUE FALSE TRUE FALSE TRUE FALSE ... Note that column 3 col3 was treated as factor and not as character, as we expected. factor is an abstraction that R uses to save categorical variables in memory in order to occupy less space. Basically, it converts categories to a number, in order to optimize memory use. If the variable is printed in the console, it does a reconversion just to present it to the user. For col3 to be really created as a character type column, we must set the stringsAsFactors = FALSE parameter. Keep this tip well, because you’ll use this same parameter when reading external data, transforming them into dataframes in R. df1 &lt;- data.frame(col1 = v6, col2 = v7, col3 = v8, col4 = v9, stringsAsFactors = FALSE) str(df1) ## &#39;data.frame&#39;: 10 obs. of 4 variables: ## $ col1: int 11 12 13 14 15 11 12 13 14 15 ## $ col2: num 0.3 0.4 0.5 0.6 0.7 0.3 0.4 0.5 0.6 0.7 ## $ col3: chr &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; ... ## $ col4: logi TRUE FALSE TRUE FALSE TRUE FALSE ... TIP: Starting from version 4.0.0, it’s no longer necessary to declare stringsAsFactors = FALSE in the data.frame function. This has become the default behavior of the function: not transforming string columns into factors. Note that, unlike vectors which were one-dimensional, dataframes are two-dimensional. We have one dimension represented by rows and another dimension represented by columns. To calculate your dataframe’s dimensions you can use the following functions: # rows vs columns dim(df1) ## [1] 10 4 # number of rows nrow(df1) ## [1] 10 # number of columns ncol(df1) ## [1] 4 1.2.2.2 How to extract elements from a Dataframe To extract Dataframe elements, we’ll use the same vector indexing technique, using brackets []. The difference is that, since the Dataframe has two dimensions, we need to work with both, separating each dimension’s indices with a comma inside the brackets df_name[row_index, column_index]. Now, the values we pass inside the brackets refer to a Dataframe’s rows or columns. It’s like playing battleship. TIP: If you want to extract only entire row(s), leave the column dimension blank, e.g.: df_name[row_X, ]. If you want to extract only column(s), leave the row dimension blank, e.g.: df_name[, column_Y]. Extracting one or more rows: # single row df1[3, ] ## col1 col2 col3 col4 ## 3 13 0.5 UNF TRUE # some rows # note comma positioning df1[c(1,2,5), ] ## col1 col2 col3 col4 ## 1 11 0.3 UNF TRUE ## 2 12 0.4 UNF FALSE ## 5 15 0.7 UNF TRUE # a sequence of rows df1[3:5, ] ## col1 col2 col3 col4 ## 3 13 0.5 UNF TRUE ## 4 14 0.6 UNF FALSE ## 5 15 0.7 UNF TRUE Extracting one or more columns: # single column df1[ ,2] ## [1] 0.3 0.4 0.5 0.6 0.7 0.3 0.4 0.5 0.6 0.7 # some columns # note comma positioning df1[, c(2,3)] ## col2 col3 ## 1 0.3 UNF ## 2 0.4 UNF ## 3 0.5 UNF ## 4 0.6 UNF ## 5 0.7 UNF ## 6 0.3 UNF ## 7 0.4 UNF ## 8 0.5 UNF ## 9 0.6 UNF ## 10 0.7 UNF # a sequence of columns df1[, 2:4] ## col2 col3 col4 ## 1 0.3 UNF TRUE ## 2 0.4 UNF FALSE ## 3 0.5 UNF TRUE ## 4 0.6 UNF FALSE ## 5 0.7 UNF TRUE ## 6 0.3 UNF FALSE ## 7 0.4 UNF TRUE ## 8 0.5 UNF FALSE ## 9 0.6 UNF TRUE ## 10 0.7 UNF FALSE Extracting specific elements, crossing rows and columns You can mix indices from both dimensions, to extract specific subsets from your Dataframe. It’s like playing battleship: # single element # element at the intersection of 2nd row and 3rd column df1[2, 3] ## [1] &quot;UNF&quot; # subsets # elements at the intersection of 2nd and 5th row vs 1st and 4th column df1[c(2,5), c(1,4)] ## col1 col4 ## 2 12 FALSE ## 5 15 TRUE # subsets # sequence from 2nd to 4th row vs sequence from 3rd to 5th row df1[1:3, 2:4] ## col2 col3 col4 ## 1 0.3 UNF TRUE ## 2 0.4 UNF FALSE ## 3 0.5 UNF TRUE TIP: You can also mix previous examples, for example: df1[2, 2:4]. 1.2.2.3 Other ways to index Dataframe columns There are two more ways to index Dataframe columns. Both use column names and not indices. First alternative way: df1[, &quot;col2&quot;] ## [1] 0.3 0.4 0.5 0.6 0.7 0.3 0.4 0.5 0.6 0.7 Second alternative way: df1$col3 ## [1] &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; &quot;UNF&quot; Note that the output is printed horizontally. This occurs because, when we extract only one column, we’re extracting a vector. And a vector’s output form is horizontal, as we saw earlier. 1.2.3 Module References Computational Statistics 2 (2015). Class notes. Statistics Course, UnB, 1st semester, 2015. Nyffenegger, R. (2020). R: a computer language for statistical data analysis. URL https://renenyffenegger.ch/notes/development/languages/R/. Wickham, H. (2014). Advanced R. September 25, 2014. Chapman and Hall/CRC. 476 Pages. Available at: https://adv-r.hadley.nz/. R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/. 1.2.4 Exercises 1) Vectors Create two numeric vectors (A and B) of size 10 with random numbers chosen by you. Multiply all items of vector A by \\(\\times3\\) and items of vector B by \\(\\times4\\). Create a new vector (C) resulting from the operation \\(\\frac{log(B)}{|A| + (A+B)}\\), where \\(|A|\\) is the size of vector A. Create a new logical vector (D), checking which values of A are greater than the respective values of B. Add 3 names chosen by you to the end of each vector. Do the vectors change type? 2) Dataframes Create a Dataframe with 10 rows and 5 columns, with at least 3 columns of different types, at least two being numeric. Create a 6th column resulting from the sum between two numeric columns of the Dataframe. Choose two numeric columns A and B, and create a 7th column resulting from the operation \\(\\frac{log(B)}{|A| + (A+B)}\\), where \\(|A|\\) is the size of column A. 3) Practice Create a character vector with the names of 5 courses offered at UNF (University of North Florida). Create a numeric vector with hypothetical enrollment numbers for each of these courses. Combine these vectors into a dataframe with appropriate column names. Extract the course with the highest enrollment using vector indexing. Calculate the total enrollment across all courses. "],["m2.html", " 2 Module II 2.1 Reading Data in R 2.2 Data Manipulation with dplyr 2.3 Graphics with ggplot2", " 2 Module II 2.1 Reading Data in R So far, we’ve been working by creating objects from data entered via script or console. However, the most common practice when doing data analysis is to read data from external sources, such as a .txt or .csv file, a relational database (SQL) on our company’s server, or even from web pages. In this section, we’ll see how to read databases stored locally on the computer. I often say that in R, there are always at least 3 different ways to perform the same task. When it comes to reading data, this is no different, since R has several packages for data reading; some focus on speed, others on practicality, and still others are made specifically to handle massive databases. Regarding this last aspect, it must be recognized that R doesn’t have memory management that allows users to load very large databases (around 10 million rows or so). This is, in a way, intentional, since R was created to make life easier for users dealing with data analysis. But it should be noted that, due to its extremely active community, several packages have been and continue to be developed with the aim of improving how R handles object storage in memory. In this course, we’ll focus on using the readr package, as we understand it to be a middle ground between practicality and speed, considering the alternatives from base R and similar but much faster functions, such as those available in the data.table, vroom packages, among others. 2.1.1 The Tidyverse readr is part of a collection of packages called Tidyverse. “The tidyverse is a set of packages that work in harmony because they share common data representations and API design. The tidyverse package is designed to make it easy to install and load core packages from the tidyverse in a single command.” * Hadley Wickham * Tidyverse Hexsticker We can define the Tidyverse, then, as a meta-package that brings together a collection of several other R packages aimed at importing, exploring, manipulating, and visualizing data. They range from packages for string manipulation, regular expressions, dates, through reading and import packages, data manipulation and visualization, to report generation and web page creation, among other things. These packages seek to provide greater standardization and ease in dealing with data in R. 2.1.2 Reading and Exporting Data using readr The goal of the readr package is to make reading rectangular/tabular databases (csv, txt, and fwf) in R easier and more user-friendly. Compared to base R alternatives, readr is smarter in the sense of trying to guess column formats, while still allowing, if necessary, user specification of patterns. The most important reading functions in the package are: read_csv(): reads .csv or .txt files in American format, where the column separator is a comma; read_csv2(): reads .csv or .txt files in European format, where the column separator is a semicolon; read_tsv(): reads .csv or .txt files, where the column separator is tab \\t; read_table(): reads .txt files, where the column separator is whitespace; read_delim(): allows reading files of various extensions, where the user can specify the delimiter through the delim parameter. Let’s practice using data from the UCI Wine Quality Dataset. You can download the data. However, since our goal is to create the reading experience, we’ll use this LINK. Once on the page, you can save it to your computer by right-clicking and then clicking Save as. Note that the data is in a .csv file in semicolon-separated format. Let’s read the file that was saved on our computer. TIP: On your computer, the file path will be different. library(readr) wine_data &lt;- read_csv2(file=&quot;C:\\\\Users\\\\...\\\\winequality-red.csv&quot;) # or using the more generic function wine_data &lt;- read_delim(file=&quot;C:\\\\Users\\\\...\\\\winequality-red.csv&quot;, delim = &quot;;&quot;) If you don’t want to save the database on your computer, reading the file directly from the website, you can also do that. Just copy the file address shown in the browser and pass it to the file argument. Paths passed to the file argument starting with http://, https://, ftp://, or ftps:// result in automatic download and reading of the file. ## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control. ## Warning: One or more parsing issues, call `problems()` on your data frame for details, e.g.: ## dat &lt;- vroom(...) ## problems(dat) ## Rows: 1599 Columns: 12 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;;&quot; ## chr (5): volatile acidity, citric acid, chlorides, density, sulphates ## dbl (2): total sulfur dioxide, quality ## num (5): fixed acidity, residual sugar, free sulfur dioxide, pH, alcohol ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Once the file is read, the functions print to the console the names of each column and the ways they were read. This allows the user to check if everything went well during reading. If any column wasn’t read in the format you expected, just copy the output and run the function again, changing the specification of that particular column. For example, let’s change the quality column from double (which takes up more memory) to be read as an integer. We make this specification in the col_types argument. wine_data &lt;- read_csv2(file=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&quot;, col_types = cols( `fixed acidity` = col_double(), `volatile acidity` = col_double(), `citric acid` = col_double(), `residual sugar` = col_double(), chlorides = col_double(), `free sulfur dioxide` = col_double(), `total sulfur dioxide` = col_double(), density = col_double(), pH = col_double(), sulphates = col_double(), alcohol = col_double(), quality = col_integer() ) ) ## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control. ## Warning: One or more parsing issues, call `problems()` on your data frame for details, e.g.: ## dat &lt;- vroom(...) ## problems(dat) Once the file is read, we can inspect it by calling the created object, or by clicking on the object name in our environment. wine_data ## # A tibble: 1,599 × 12 ## `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides `free sulfur dioxide` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NA NA 0 NA NA 11 ## 2 NA NA 0 NA NA 25 ## 3 NA NA NA NA NA 15 ## 4 NA NA NA NA NA 17 ## 5 NA NA 0 NA NA 11 ## 6 NA NA 0 NA NA 13 ## 7 NA NA NA NA NA 15 ## 8 NA NA 0 NA NA 15 ## 9 NA NA NA 2 NA 9 ## 10 NA NA NA NA NA 17 ## # ℹ 1,589 more rows ## # ℹ 6 more variables: `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, ## # quality &lt;int&gt; Note that this file doesn’t look much like the classic Dataframe format we saw in Module 1. It’s actually a new type of object, which follows the Tidyverse philosophy, commented on in the previous section. We have here a tibble, which is nothing more than a friendlier Dataframe. In general terms, the difference between a classic Dataframe and a tibble is mainly in the information presented to us when we print the object’s content to the console. Unlike a Dataframe, a tibble shows us only the first 10 rows of the table, the column types, and only the content of columns that fit on our screen. Another difference is in the result when we perform indexing. We can still use [row_index, column_index] or dataframe_name$column_name. The thing is that indexing with brackets will return a tibble, even if the operation results in a single column. Indexing via $ will return a vector. In summary, the first doesn’t change the object type - we continue with a tibble. The second changes the object type. Test this in practice: wine_data[,&quot;quality&quot;] # or wine_data[,12] wine_data$quality Other advantages of tibble are: we no longer need to worry about stringsAsFactors=FALSE; it works much more fluidly with the other tidyverse packages we’ll use later in the course; 2.1.2.1 Alternatives When it comes to reading data, there are many alternatives in R. Although not within the scope of this course, we suggest you study how the read.table() family functions from base R work. These functions are slower than readr package functions, but offer greater flexibility regarding parameter specification. Regarding large databases, with millions of observations, we suggest the fread() function from the data.table package. But this speed comes with the price of having to learn a slightly different programming paradigm, even though it’s within R. Many people are also interested in reading data from Excel spreadsheets or sheet tabs in .xls and .xlsx formats. Although it’s not the most appropriate way to store data, it’s worth knowing there’s an alternative for reading Excel data. Read about the readxl package and the read_excel() function. 2.1.3 Writing and exporting data Despite its name, the readr package also has functions for writing data. To export the results of our analyses in R to a table with .txt or .csv extension, for example, we’ll use functions very similar to reading ones, changing only the prefixes from read to write. The suffixes, again, will depend on the type of file you want to save. The most used functions are: write_csv(); write_csv2; write_table(); and write_delim(). Let’s modify the wine_data file and then export the new version as a new .csv file in European format. Using the knowledge about object indexing from Module 1, let’s replace the first 500 rows of the quality column to 8, and eliminate a column. 1) changing the quality wine_data[1:500, &quot;quality&quot;] &lt;- rep(8, 500) # or wine_data[1:500, 12] &lt;- rep(8, 500) # or wine_data$quality[1:500] &lt;- rep(8, 500) 2) excluding the first column In R, we have a word reserved by the language that transforms objects or object elements into empty. It’s the word NULL. wine_data[, &quot;fixed acidity&quot;] &lt;- NULL # or wine_data[, 1] &lt;- NULL # or wine_data_modified &lt;- wine_data[, 2:ncol(wine_data)] # we replace the complete version of the tibble with a version that brings... #...only data from column 2 onwards 3) saving the new tibble in a file write_csv2(x=wine_data, path=&quot;C://path//...//wine_data_modified.csv&quot;) # or write_delim(x=wine_data, path=&quot;C://path//...//wine_data_modified.csv&quot;, delim=&quot;;&quot;) TIP: It’s very common to have doubts about what the parameters of a function are and how it works. Don’t forget to always consult R’s Help, or type the function_name in the Console to see all its parameters. 2.1.4 Reading data from Stata, SAS and SPSS We’ve seen that in these 20 years of history, R has grown considerably. During this time, several researchers and professionals from various areas migrated to R, mainly from Stata, SAS, and SPSS. When facing the cost of change, many people encounter the challenge of “translating” their scripts from one language to another, as well as reading data written or stored in extensions used by those languages. R’s standard installation already offers a library to read databases from other languages. The package name makes perfect sense: foreign. It brings several functions that make importing simple. Additionally, installing and using the Hmisc package is also recommended. Below, we present just some ideas on how to handle “foreign” datasets in R: SPSS: # saving the dataset in SPSS in transport format (XPORT) get file=&#39;C:/my_data.sav&#39;. export outfile=&#39;C:/my_data.por&#39;. # in R # install.packages(&quot;Hmisc&quot;) # if necessary library(Hmisc) df &lt;- spss.get(&quot;C:/my_SPSS_data.por&quot;, use.value.labels=TRUE) # use.value.labels=TRUE converts label values to factors SAS: # save the SAS dataset in transport format (XPORT) libname out xport &#39;C:/my_SAS_data.xpt&#39;; data out.mydata; set sasuser.mydata; run; # in R library(Hmisc) mydata &lt;- sasxport.get(&quot;C:/my_SAS_data.xpt&quot;) # character type variables will be converted to factors Stata: library(foreign) mydata &lt;- read.dta(&quot;C:/my_stata_data.dta&quot;) 2.1.5 Section References Quick R website. (2020). URL https://www.statmethods.net/. Wickham, H.; Hester, J.; François R. (2018). readr: Read Rectangular Text Data. R package version 1.3.1. URL https://CRAN.R-project.org/package=readr. ____. (2020). readr official website. URL https://readr.tidyverse.org/index.html. Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: https://www.r4ds.co.nz. 2.2 Data Manipulation with dplyr In this section, we’ll cover the dplyr package, which is one of the most important packages in the tidyverse collection. It brings a specific “grammar” of data manipulation, providing a set of functions that help solve the most common challenges in data manipulation. The goal is for you to become familiar with dplyr package functions; with the tasks they perform; and see examples of how to apply them to data.frames. As the package authors themselves point out, when we work with data, we need to: Discover what we want to do; Describe these tasks in the form of a computer program; Execute the program. The dplyr package makes these steps faster and easier to execute, because: instead of providing a multitude of functions, like we have in base R and other packages, it restricts our options and thereby helps us think more directly about what we want and can do with the data; provides simpler “verbs” (or functions), i.e., functions that correspond to the most common data manipulation tasks, helping us translate thoughts into code; uses efficient backends (end-process codes, i.e., closer to the user), so we spend less time waiting for the computer. The dplyr package provides a function for each “verb” considered important in data manipulation: filter() to select “cases” based on their values; arrange() to reorder “cases”; select() and rename() to select variables based on their names; mutate() and transmute() to add new variables that are functions of variables already existing in the data; summarise() or summarize() to condense multiple values into a single one; group_by() although not considered one of the “verbs”, serves to group data around one or more variables. Functions considered “verbs” can be used before or after data grouping. We’ll now see some examples of applying these functions. Let’s use a different dataset now. We’ll use the built-in mtcars dataset that comes with R, which contains information about car models. library(dplyr) # Load the mtcars dataset cars_data &lt;- as_tibble(mtcars) dim(cars_data) ## [1] 32 11 Note that by print we again have a tibble, which is a modern form of data.frame implemented by the tidyverse folks. This format is particularly useful for large datasets because only the first lines and various summaries/information about our variables are printed on screen. To convert data.frames to tibbles, we use as_tibble(). 2.2.1 Filtering rows with filter() filter() allows making a subset of rows from a tibble/dataframe. Like all simple verbs in dplyr, the first argument will be a tibble (or data.frame). The second argument and subsequent ones refer to variables within the data.frame, where rows are selected where the expression is true (TRUE). Let’s select all rows where miles per gallon (mpg) is greater than 20 and the number of cylinders is 4: filter(cars_data, mpg &gt; 20, cyl == 4) ## # A tibble: 11 × 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 2 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 3 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.2 19.5 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.62 18.5 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.84 19.9 1 1 4 1 ## 7 21.5 4 120. 97 3.7 2.46 20.0 1 0 3 1 ## 8 27.3 4 79 66 4.08 1.94 18.9 1 1 4 1 ## 9 26 4 120. 91 4.43 2.14 16.7 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 ## 11 21.4 4 121 109 4.11 2.78 18.6 1 1 4 2 TIP: In base R, this would be equivalent to the code: cars_data[cars_data$mpg &gt; 20 &amp; cars_data$cyl == 4, ]. 2.2.2 Ordering rows with arrange() arrange() works similarly to filter, but instead of filtering and selecting rows, it just reorders them according to some condition we pass. This function takes a data.frame and a set of column names by which it will sort. If you provide more than one column name, each additional column passed will be used as a tiebreaker. arrange(cars_data, cyl, mpg, hp) ## # A tibble: 32 × 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21.4 4 121 109 4.11 2.78 18.6 1 1 4 2 ## 2 21.5 4 120. 97 3.7 2.46 20.0 1 0 3 1 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 5 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 6 26 4 120. 91 4.43 2.14 16.7 0 1 5 2 ## 7 27.3 4 79 66 4.08 1.94 18.9 1 1 4 1 ## 8 30.4 4 75.7 52 4.93 1.62 18.5 1 1 4 2 ## 9 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 ## 10 32.4 4 78.7 66 4.08 2.2 19.5 1 1 4 1 ## # ℹ 22 more rows If you want to sort in descending order, use the desc(column_name) function inside arrange(). This would be particularly interesting if you wanted to sort data in the final column from highest to lowest. 2.2.3 Selecting columns with select() We usually work with large datasets with many columns, but only a few columns will be of interest. select() allows us to quickly focus on a subset of the data. The best part is that we can use operations - which normally only work with column positions - directly on variable names. # Selection by name select(cars_data, mpg, cyl, hp) ## # A tibble: 32 × 3 ## mpg cyl hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 110 ## 2 21 6 110 ## 3 22.8 4 93 ## 4 21.4 6 110 ## 5 18.7 8 175 ## 6 18.1 6 105 ## 7 14.3 8 245 ## 8 24.4 4 62 ## 9 22.8 4 95 ## 10 19.2 6 123 ## # ℹ 22 more rows # Selecting all columns in a range (inclusive) select(cars_data, mpg:wt) ## # A tibble: 32 × 6 ## mpg cyl disp hp drat wt ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 ## 2 21 6 160 110 3.9 2.88 ## 3 22.8 4 108 93 3.85 2.32 ## 4 21.4 6 258 110 3.08 3.22 ## 5 18.7 8 360 175 3.15 3.44 ## 6 18.1 6 225 105 2.76 3.46 ## 7 14.3 8 360 245 3.21 3.57 ## 8 24.4 4 147. 62 3.69 3.19 ## 9 22.8 4 141. 95 3.92 3.15 ## 10 19.2 6 168. 123 3.92 3.44 ## # ℹ 22 more rows # Selecting all columns except those in a range (inclusive) select(cars_data, -(mpg:wt)) ## # A tibble: 32 × 5 ## qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16.5 0 1 4 4 ## 2 17.0 0 1 4 4 ## 3 18.6 1 1 4 1 ## 4 19.4 1 0 3 1 ## 5 17.0 0 0 3 2 ## 6 20.2 1 0 3 1 ## 7 15.8 0 0 3 4 ## 8 20 1 0 4 2 ## 9 22.9 1 0 4 2 ## 10 18.3 1 0 4 4 ## # ℹ 22 more rows TIP: There are helper functions we can use inside select(). They are functions that resemble the functioning of a regular expression (a concept we’ll see in Module 3) to identify column names that meet a certain criterion. They’re very useful with large datasets: starts_with(), ends_with(), matches() and contains(). Let’s for example select all columns that start with “d”: select(cars_data, starts_with(&quot;d&quot;)) ## # A tibble: 32 × 2 ## disp drat ## &lt;dbl&gt; &lt;dbl&gt; ## 1 160 3.9 ## 2 160 3.9 ## 3 108 3.85 ## 4 258 3.08 ## 5 360 3.15 ## 6 225 2.76 ## 7 360 3.21 ## 8 147. 3.69 ## 9 141. 3.92 ## 10 168. 3.92 ## # ℹ 22 more rows select() can even be used to rename variables: select(cars_data, miles_per_gallon = mpg) ## # A tibble: 32 × 1 ## miles_per_gallon ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ℹ 22 more rows The new variable will be called miles_per_gallon and will receive all information from the original mpg. However, select() “abandons” all other variables when you do a renaming. It’s better then to use rename(): rename(cars_data, miles_per_gallon = mpg) ## # A tibble: 32 × 11 ## miles_per_gallon cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ℹ 22 more rows 2.2.4 Adding new columns with mutate() In addition to selecting sets of existing columns, it’s generally useful to add new columns that are functions of columns already present in the tibble/dataframe. See an example with mutate(), where we want to calculate the power-to-weight ratio: mutate(cars_data, power_to_weight = hp / wt ) ## # A tibble: 32 × 12 ## mpg cyl disp hp drat wt qsec vs am gear carb power_to_weight ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 42.0 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 38.3 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 40.1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 34.2 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 50.9 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 30.3 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 68.6 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 19.4 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 30.2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 35.8 ## # ℹ 22 more rows mutate() even allows us to refer to columns we just created in the same command. Let’s save this change in a new tibble, called cars_data2 cars_data2 &lt;- mutate(cars_data, power_to_weight = hp / wt, power_to_weight_scaled = power_to_weight * 100 ) If we’re only interested in the new variables, we would use transmute(): transmute(cars_data, power_to_weight = hp / wt, power_to_weight_scaled = power_to_weight * 100 ) ## # A tibble: 32 × 2 ## power_to_weight power_to_weight_scaled ## &lt;dbl&gt; &lt;dbl&gt; ## 1 42.0 4198. ## 2 38.3 3826. ## 3 40.1 4009. ## 4 34.2 3421. ## 5 50.9 5087. ## 6 30.3 3035. ## 7 68.6 6863. ## 8 19.4 1944. ## 9 30.2 3016. ## 10 35.8 3576. ## # ℹ 22 more rows 2.2.5 Modifying entries with mutate() or transmute() + case_when() case_when() is a function from the dplyr package that allows us to modify variables from a sequence of conditions that must be respected. IF CONDITION1 TRUE ~ DO SUCH THING; ELSE ~ DO ANOTHER THING It replaces R’s native conditional structures (ifelse() function) and is inspired by the equivalent statement in SQL CASE WHEN. The arguments of the case_when() function follow the following structure: conditional operation ~ new value. On the left side of ~, you have the comparison to be made. On the right side, we have the new value to be assigned if the comparison result is TRUE. You can even handle more than one condition, as long as you go from the most specific case to the most general. case_when( condition1 ~ &quot;new_value1&quot;, condition2 ~ &quot;new_value2&quot;, condition3 ~ &quot;new_value3&quot;, TRUE ~ &quot;value for other cases not met by conditions above&quot; ) Generally, in the context of data analysis with dplyr, we use case_when() inside a mutate() or transmute function (which brings only the newly created column), since we intend to change column entries, thus changing the column itself. In the cars_data2 tibble, let’s create a new character column called efficiency_level, where we’ll classify efficiency as: high if mpg &gt; 20; low if mpg &lt; 15 or moderate in other cases: transmute(cars_data2, efficiency_level = case_when( mpg &gt; 20 ~ &quot;high&quot;, mpg &lt; 15 ~ &quot;low&quot;, TRUE ~ &quot;moderate&quot; )) ## # A tibble: 32 × 1 ## efficiency_level ## &lt;chr&gt; ## 1 high ## 2 high ## 3 high ## 4 high ## 5 moderate ## 6 moderate ## 7 low ## 8 high ## 9 high ## 10 moderate ## # ℹ 22 more rows TIP: If newly created column values are displayed in exponential (scientific) notation, run the code below to force decimal places to be displayed in conventional mode and then print the columns again. # scipen is a kind of penalty for using exponential notation values # positive values penalize exponential notation display # negative values penalize fixed/regular notation display options(scipen=999) 2.2.6 Summarizing values with summarise() The last dplyr “verb” is summarise() (or summarize). It collapses a tibble/dataframe into a single row. summarise(cars_data2, mean_mpg = mean(mpg, na.rm = TRUE) ) ## # A tibble: 1 × 1 ## mean_mpg ## &lt;dbl&gt; ## 1 20.1 TIP: The na.rm = TRUE parameter inside the mean() function makes it disregard missing values (NA) when calculating the mean. Otherwise, in the existence of missing values NA, the function will always return NA. This also applies to other vectorized mathematical functions, like sum(), for example. Depending on your goal, it may be more useful to use the “verb” group_by() which we’ll see later. With it we can calculate the average by category, i.e., by number of cylinders, transmission type, etc. 2.2.7 dplyr Structure Note that the syntax and functioning of all dplyr verbs presented so far are quite similar: the first argument is a tibble/dataframe; subsequent arguments describe what to do with the data. We can refer to tibble/dataframe columns directly without the need to use $ or [] indexing. the result is a new tibble/dataframe. Together, these properties make it easy to chain multiple simple steps to achieve a complex result. The rest of what dplyr does comes from applying the 5 functions we’ve seen so far to different types of data. Instead of working with disaggregated data, we’ll now start working with data grouped by one or more variables. 2.2.7.1 Grouped operations The dplyr verbs become even more powerful when we apply them to groups of observations within a dataset. We do this with the group_by() function. It “breaks” the dataset into specific groups of rows. At first, we don’t see any change. It’s as if they stay in the background. However, when we apply any of the main verbs to the dataset “altered” by group_by, they will automatically be applied by group or “by group”. Using grouping affects the result of main verbs as follows: grouped select() is the same as ungrouped, except that grouping variables are always preserved. grouped arrange() is the same as ungrouped, unless we use .by_group = TRUE, in which case it sorts first by grouping variables; mutate() and filter() are quite useful together with window functions (like rank() or min(x) == x) (See dplyr “window-functions” vignette); summarise() calculates the summary for each group. In the following example, we separate the dataset by cyl, counting the number of records for each number of cylinders (count = n()), computing the average miles per gallon by cylinder group (mean_mpg = mean(mpg, na.rm = TRUE)). by_cyl &lt;- group_by(cars_data2, cyl) summary_by_cyl &lt;- summarise( by_cyl, count = n(), mean_mpg = mean(mpg, na.rm = TRUE) ) summary_by_cyl ## # A tibble: 3 × 3 ## cyl count mean_mpg ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 4 11 26.7 ## 2 6 7 19.7 ## 3 8 14 15.1 Note that summarise() is normally used with aggregate functions, which take a vector of values and return a single number. There are many useful examples from base R that can be used, such as min(), max(), mean(), sum(), sd(), median(), etc. dplyr provides some other very useful ones: n(): number of observations in the current group; n_distinct(x): number of unique values in x; first(x), last(x) and nth(x, n) work similarly to x[1], x[length(x)] and x[n], but give us more control over the result if any value is missing. See an example where we use these functions to find the number of distinct transmission types for each cylinder group and total number of cars: by_cyl_am &lt;- group_by(cars_data2, cyl) summarise(by_cyl_am, n_transmission_types = n_distinct(am), total_cars = n() ) ## # A tibble: 3 × 3 ## cyl n_transmission_types total_cars ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 4 2 11 ## 2 6 2 7 ## 3 8 2 14 When we group more than one variable, each summarise() we execute eliminates one level of grouping. Example: by_cyl_am &lt;- group_by(cars_data2, cyl, am) (summary_by_am &lt;- summarise(by_cyl_am, count = n())) ## `summarise()` has grouped output by &#39;cyl&#39;. You can override using the `.groups` argument. ## # A tibble: 6 × 3 ## # Groups: cyl [3] ## cyl am count ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 4 0 3 ## 2 4 1 8 ## 3 6 0 4 ## 4 6 1 3 ## 5 8 0 12 ## 6 8 1 2 # note that from the &quot;Groups:&quot; description of the tibble, i.e., the number of grouping variables decreases (summary_by_cyl &lt;- summarise(summary_by_am, count = sum(count))) ## # A tibble: 3 × 2 ## cyl count ## &lt;dbl&gt; &lt;int&gt; ## 1 4 11 ## 2 6 7 ## 3 8 14 2.2.7.2 Care with variable names One of the best features of the dplyr package is that we can refer to variables in a tibble or dataframe as if they were regular variables (those in the Global Environment). However, the reference syntax for column names hides some differences between verbs. For example, a column name or value passed to select() doesn’t have the same meaning as it would in mutate(). See equivalent forms from dplyr’s point of view: select(cars_data2, mpg) ## # A tibble: 32 × 1 ## mpg ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ℹ 22 more rows select(cars_data2, 1) ## # A tibble: 32 × 1 ## mpg ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ℹ 22 more rows If there’s a variable in the Global Environment with the same name as a column in our tibble/dataframe, dplyr will prioritize the variable that’s in the tibble. mpg &lt;- 5 select(cars_data2, mpg) ## # A tibble: 32 × 1 ## mpg ## &lt;dbl&gt; ## 1 21 ## 2 21 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ℹ 22 more rows This behavior only applies to “raw” names and selection calls like select(tibble, var1, var2, var3) or var1:var3. In all other cases, tibble column names are preferred over “loose” variables in the Global Environment. var1 &lt;- &quot;c&quot; select(cars_data2, starts_with(var1)) ## # A tibble: 32 × 2 ## cyl carb ## &lt;dbl&gt; &lt;dbl&gt; ## 1 6 4 ## 2 6 4 ## 3 4 1 ## 4 6 1 ## 5 8 2 ## 6 6 1 ## 7 8 4 ## 8 4 2 ## 9 4 2 ## 10 6 4 ## # ℹ 22 more rows Note that in this last case, dplyr looked at the content of the var1 variable and not the literal variable name. 2.2.8 Using the Pipe %&gt;% dplyr is functional in the sense that function calls have no side effects. That is, you always need to save your results. This makes our code not so elegant, especially when we’re going to do several operations, one at a time: # grouping by cyl, am level1 &lt;- group_by(cars_data2, cyl, am) # selecting only columns mpg, hp, power_to_weight level2 &lt;- select(level1, mpg, hp, power_to_weight) # calculating total car count and average horsepower by group level3 &lt;- summarise(level2, total_cars = n(), avg_hp = mean(hp, na.rm = TRUE) ) # filtering groups with car count above 5 level4 &lt;- filter(level3, total_cars &gt; 5) Note that there are many intermediate results we’re saving, when actually we’d only be interested in the final one. To solve this we could call one function inside another: filter( summarise( select( group_by(cars_data2, cyl, am), mpg, hp, power_to_weight ), total_cars = n(), avg_hp = mean(hp, na.rm = TRUE) ), total_cars &gt; 5 ) Although it solves the problem of saving intermediate objects, this approach is difficult to read the steps because the order of operations goes from inside to outside. So, arguments end up being far from the function itself. To give an elegant solution to the problem, dplyr uses the pipe operator %&gt;% from the magrittr package. x %&gt;% f() is equivalent to f(x). So, we can use this operator to rewrite multiple operations that we can read from left to right and top to bottom. It’s as if each line of code functioned as a distinct department of a company. Production begins on the first line. Once changes in this first department are finished, the unfinished product (data) is “thrown” to the department below via the pipe, where production continues. From there it goes to the next department, and so on until all data changes have been made. cars_data2 %&gt;% group_by(cyl, am) %&gt;% select(mpg, hp, power_to_weight) %&gt;% summarise( total_cars = n(), avg_hp = mean(hp, na.rm = TRUE) ) %&gt;% filter(total_cars &gt; 5) ## Adding missing grouping variables: `cyl`, `am` ## `summarise()` has grouped output by &#39;cyl&#39;. You can override using the `.groups` argument. ## # A tibble: 2 × 4 ## # Groups: cyl [2] ## cyl am total_cars avg_hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 4 1 8 81.9 ## 2 8 0 12 194. TIP: Note that the tibble or dataframe name only needs to be informed once at the beginning of the process. 2.2.9 Section References Wickham H.; François, R.; Henry, L.; Müller K. (2019). dplyr: A Grammar of Data Manipulation. R package version 0.8.1. URL https://CRAN.R-project.org/package=dplyr. Wickham H.; François, R.; Henry, L.; Müller K. (2020). dplyr vignette: Introduction. URL http://dplyr.tidyverse.org. Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: https://www.r4ds.co.nz. 2.2.10 Exercises Import the iris dataset (built-in R dataset) or download a dataset from UCI Machine Learning Repository. What is the average sepal length by species? Write a new txt or csv table with this data. Group the data by species and save a separate table (txt or csv) for each grouping. TIP: Research about how to split dataframes by groups with dplyr and how to index lists. Identify the species with the longest average petal length. Create and save a new table containing the count of observations by species. 2.3 Graphics with ggplot2 In this section we’ll see how to make sophisticated graphics in R. These will be just the basics, since ggplot2 provides the user with total control of almost all aspects of a graph. However, they’ll already be sufficient tools to create and customize various graphics in R. The number of types of graphics we can make with ggplot2 is immeasurable. The idea is to understand the basic and structural concepts of the package and then walk on our own legs. 2.3.1 Introduction The ggplot2 package creates graphics using layers of attributes, using the so-called grammar of graphics. This grammar allows building graphics component by component instead of having to edit “prefabricated” graphics as occurs in base R and all other libraries of languages used for Data Science, like matplotlib and seaborn from Python, for example. We don’t need to know the grammar to start producing graphics with ggplot2. However, by understanding the structure of the grammar of graphics, we can: build graphics from concepts (of what we want to do) instead of having to remember commands and options; conceive new and improved graphics. ggplot2, although it arose before tidyverse, is also one of the packages from the core of this meta-package. It was written by Hadley Wickham, who published the book titled “ggplot2 Elegant Graphics for Data Analysis”. The success of ggplot2 is so expressive that APIs (Application Programming Interface) were made so that the package’s functionalities could be used in other languages, like Python for example. 2.3.2 The grammar of graphics The grammar of graphics was a concept developed by Leland Wilkinson in 1999 and published by him in The Grammar of Graphics in 2005. This grammar defines rules for structuring mathematical and aesthetic elements (aesthetics) in a graphic itself. ggplot2 is written under the rules of this grammar. 2.3.2.1 Structure of the grammar of graphics in ggplot2: data data containing variables to be plotted; variables to be portrayed in the graph; variables to be mapped to the aesthetics (perceptible elements) of the graph; Geoms (geometric shapes) objects and shapes of the graph (bars, points, lines, etc) Stats statistical transformations, generally to summarize data (mean, variance, median, etc) Scales defines which aesthetic elements (aesthetics) of the graph will be mapped to variables (e.g.: which colors will be mapped to which values) Coordinate Systems defines how data will be mapped to the graph plane/area (Cartesian, Polar, etc) Facetting divides data into subsets to create multiple variations of the same graph (e.g.: panel graphs) All these elements are treated as layers and can be added to the main part of the graph using the + sign. In this course, we’ll see in more detail the data, aesthetics, stats and facetting elements and what each of these elements means in the structure of the grammar of graphics. We’ll use the mtcars and iris datasets that come built-in with R. Let’s load the necessary packages and prepare our data. library(readr) library(magrittr) library(ggplot2) # Using the mtcars dataset cars_data &lt;- as_tibble(mtcars) # Using the iris dataset iris_data &lt;- as_tibble(iris) 2.3.3 Data Data used with ggplot2 functions MUST be stored as a tibble or dataframe. There’s even the possibility of using more than one dataframe in a graph. The recommendation is to define and be sure about variable types (numeric, factor, etc) before starting to build a graph. 2.3.4 The ggplot() function The data to be used for plotting will be specified inside the ggplot() function. Note that it’s ggplot() and not ggplot2(). Our data.frame or tibble will always be the first argument of this function. Another argument to be passed to the ggplot() function are the aesthetics, using the auxiliary function aes() which maps data variables to perceptible graphic elements (aesthetic), such as position on graph axes, definition of colors by categories, etc. Any subsequent function will inherit the data and aesthetics from ggplot(), unless these parameters are overwritten in another layer. To chain other functions to the ggplot() function, we always use +. 2.3.5 Aesthetics (aesthetic elements of graphics) Variables are mapped to aesthetics, which means they are translated to graphic aesthetic elements. The aes() function, as we’ve seen, does this mapping. It can also be specified within other layers that make up the graph, such as geoms or stats, for example. The most used aesthetics are: x - position on x-axis; y - position on y-axis; color or colour - “outside color” or object outline; fill - “inside color” of object; alpha - graph transparency level; shape - marker shapes (points, triangles, cross, etc); size - size (radius) of objects. 2.3.6 Examples for aesthetics To make a graph, we first need to indicate the data and map variables to aesthetics. This reserves a graph area to be used. options(scipen= 999) # to avoid exponential notation display cars_data %&gt;% ggplot(data=cars_data, mapping = aes(x=wt, y=mpg)) Let’s see a first example for the relationship between weight (wt) and miles per gallon (mpg). cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg)) + geom_point() Note that there was no need to re-specify the data and aes() arguments for the geom_point() function. We could improve our graph by adding colors inside aes(). This would add more information. We could assign different colors for each number of cylinders: cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg)) + geom_point(aes(color=factor(cyl))) # or # cars_data %&gt;% # ggplot(mapping = aes(x=wt, y=mpg, color=factor(cyl))) + # geom_point() We can assign different intensities to points, depending on the value of a third variable (preferably continuous between 0 and 1), using the alpha argument. Let’s create a continuous variable by simulating values within a Normal probability distribution (\\(N(0,1)\\)): # simulating values cars_data2 &lt;- cars_data %&gt;% mutate(sim_value = rnorm(n()), prob_sim = pnorm(sim_value) ) cars_data2 %&gt;% ggplot(mapping = aes(x=wt, y=mpg, alpha=prob_sim)) + geom_point() ## Warning in grid.Call.graphics(C_points, x$x, x$y, x$pch, x$size): semi-transparency is not supported on this ## device: reported only once per page In our case, this graph isn’t very useful because we have several overlapping points and this makes it difficult to perceive how colors are varying. However, it serves to illustrate this possibility with ggplot2. A better way to demonstrate different cylinder numbers would be to use different shapes (shape argument): cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg, shape=factor(cyl))) + geom_point() 2.3.6.1 Mapping vs Setting aesthetics In the previous examples, we could choose to use only a single color or single shape that wasn’t the default “dot” in black. What we should do then, instead of mapping variables to aesthetic, is set the aesthetic as constant. When we’re going to map an aesthetic, variables are passed inside aes(); whereas when we’re going to set an aesthetic as constant, the value is passed outside aes(). Let’s see the previous examples with a constant aesthetic for color and shape: cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg)) + geom_point(color = &quot;red&quot;) cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg)) + geom_point(shape = 2) Note that we must pass constants to geom_point() (outside aes()) - the geometric objects function - and not to ggplot(). See how many shapes we can use in R: d=data.frame(p=c(0:25,32:127)) ggplot() + scale_y_continuous(name=&quot;&quot;) + scale_x_continuous(name=&quot;&quot;) + scale_shape_identity() + geom_point(data=d, mapping=aes(x=p%%16, y=p%/%16, shape=p), size=5, fill=&quot;red&quot;) + geom_text(data=d, mapping=aes(x=p%%16, y=p%/%16+0.25, label=p), size=3) # http://sape.inf.usi.ch/quick-reference/ggplot2/shape Be careful when setting an aesthetic as constant inside aes(), as this can result in unexpected behavior. cars_data %&gt;% ggplot(mapping = aes(x=wt, y=mpg)) + geom_point(aes(color = &quot;green&quot;)) Although we set the color as \"green\", having done it inside aes() makes ggplot treat it differently. 2.3.7 Geoms Geoms are the geometric shapes to be plotted in graphs, example geom_line(), geom_col(), geom_point(), etc. They differ from each other in the types of aesthetics they require or understand. For example: geom_point() requires aes(x, y), whereas geom_bar() requires aes(x) only. To get help type ?geom_x. 2.3.8 Examples for Geoms geoms for one numerical variable (preferably continuous) c &lt;- cars_data2 %&gt;% ggplot(mapping = aes(x=sim_value)) TIP: Note that we can assign the graph result to an object in R and add other layers later. c + geom_density() c + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value `binwidth`. geoms for one discrete numerical variable # count cars_data %&gt;% ggplot(mapping = aes(x=factor(cyl))) + geom_bar() geoms for two variables (continuous) geom_point() can also be used in this case: e &lt;- cars_data %&gt;% ggplot(mapping=aes(x=wt, y=mpg)) e + geom_point() geoms for two variables (one qualitative and one numerical) The graphs below are ideal for checking how values are distributed, separating them into different categories. f &lt;- cars_data %&gt;% ggplot(mapping=aes(factor(cyl), mpg)) f + geom_boxplot() f + geom_violin() geoms for line plots For line plots, it’s best to use actual time series data. Let’s use the economics dataset that comes with ggplot2, which contains US economic data over time. # The economics dataset has US economic time series data data(economics) # Simple line plot of unemployment over time ggplot(economics, aes(x = date, y = unemploy)) + geom_line() + labs(title = &quot;US Unemployment Over Time&quot;, x = &quot;Date&quot;, y = &quot;Number of Unemployed (in thousands)&quot;) We can also plot multiple variables on the same graph. Let’s compare unemployment and personal savings rate: library(tidyr) # First, we need to reshape the data to long format economics_long &lt;- economics %&gt;% select(date, unemploy, psavert) %&gt;% pivot_longer(cols = c(unemploy, psavert), names_to = &quot;variable&quot;, values_to = &quot;value&quot;) # This won&#39;t work well because the scales are different # We&#39;ll normalize the data first economics_normalized &lt;- economics %&gt;% select(date, unemploy, psavert) %&gt;% mutate(unemploy_scaled = scale(unemploy), psavert_scaled = scale(psavert)) %&gt;% select(date, unemploy_scaled, psavert_scaled) %&gt;% pivot_longer(cols = c(unemploy_scaled, psavert_scaled), names_to = &quot;variable&quot;, values_to = &quot;value&quot;) ggplot(economics_normalized, aes(x = date, y = value, color = variable)) + geom_line() + labs(title = &quot;US Economic Indicators (Normalized)&quot;, x = &quot;Date&quot;, y = &quot;Standardized Value&quot;, color = &quot;Indicator&quot;) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), labels = c(&quot;Personal Savings Rate&quot;, &quot;Unemployment&quot;)) For line graphs, instead of using different colors, we could also change the line type according to categories of a variable, through the linetype argument: ggplot(economics_normalized, aes(x = date, y = value, linetype = variable)) + geom_line() + labs(title = &quot;US Economic Indicators (Normalized)&quot;, x = &quot;Date&quot;, y = &quot;Standardized Value&quot;, linetype = &quot;Indicator&quot;) + scale_linetype_manual(values = c(&quot;solid&quot;, &quot;dashed&quot;), labels = c(&quot;Personal Savings Rate&quot;, &quot;Unemployment&quot;)) Another time series example: Air Passengers The AirPassengers dataset shows monthly totals of international airline passengers from 1949 to 1960: # Convert to data frame air_df &lt;- data.frame( date = as.Date(paste(rep(1949:1960, each = 12), rep(1:12, 12), &quot;01&quot;, sep = &quot;-&quot;)), passengers = as.numeric(AirPassengers) ) ggplot(air_df, aes(x = date, y = passengers)) + geom_line(color = &quot;steelblue&quot;, linewidth = 1) + labs(title = &quot;Monthly International Air Passengers (1949-1960)&quot;, x = &quot;Date&quot;, y = &quot;Number of Passengers (thousands)&quot;) + theme_minimal() Combining lines and points: # Let&#39;s look at just the last few years of economics data recent_econ &lt;- economics %&gt;% filter(date &gt;= as.Date(&quot;2010-01-01&quot;)) ggplot(recent_econ, aes(x = date, y = unemploy)) + geom_line(color = &quot;darkblue&quot;) + geom_point(color = &quot;red&quot;, size = 1) + labs(title = &quot;US Unemployment (2010-2015)&quot;, x = &quot;Date&quot;, y = &quot;Number of Unemployed (thousands)&quot;) + theme_light() TIP: There are also other geoms you’ll find on the help page. 2.3.8.1 Positions An aspect of ggplot2 graphics that doesn’t quite become a layer, but which will be important for us to observe concerns position adjustments. They’ll be very important for bar charts with two variables. Position adjustments will define how geoms are located in the graph, so they don’t occupy the same space. In the bar chart example, we can make juxtaposed or stacked bar charts. -position=\"stack\" is the default adjustment of geom_bar(). It places each object in the exact position of the graph context. In the case of bar charts, we’d have stacked bars (stacked): iris_data %&gt;% ggplot(mapping=aes(x=Species, fill=cut(Sepal.Length, 3))) + geom_bar(position=&quot;stack&quot;) # or simply geom_bar() position = “dodge” places overlapping objects side by side. In this case, we’ll have juxtaposed bars: gg_bars &lt;- iris_data %&gt;% ggplot(mapping=aes(x=Species, fill=cut(Sepal.Length, 3))) + geom_bar(position=&quot;dodge&quot;) gg_bars TIP: If you want to invert graph coordinates, you can do this by swapping the x and y parameters in aes(), or using the coord_flip() function: gg_bars + coord_flip() position=“fill” will also stack elements, but will normalize the height of all bars so they’re on the same scale. This makes it easier to compare proportions between groups: iris_data %&gt;% ggplot(mapping=aes(x=Species, fill=cut(Sepal.Length, 3))) + geom_bar(position=&quot;fill&quot;) position=“jitter” is useful for scatter plots, since there’s a very common problem in this type of graph which is point overlap (overplotting). With jitter, ggplot2 adds random noise to X and Y positions so they don’t overlap: cars_data %&gt;% ggplot(mapping=aes(x=wt, y=mpg)) + geom_point(position=&quot;jitter&quot;) There are other very useful position adjustments, such as: position=“nudge” moves labels away from points; position=“identity” overlaps elements on top of each other. 2.3.9 Facetting Facets in ggplot2 allow us to create multiple graphics based on data subsets and plot them in the same area. It’s a very useful technique (when we have categorical variables) and we want to visualize the behavior of different categories in the same graph. There are two functions that allow creating facets: facet_wrap() and facet_grid(). Both facet_wrap and facet_grid allow splitting the plot of variable(s) passed in aes() according to categories of a 3rd or 3rd and 4th variables. cars_data %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg)) + facet_wrap(am ~ cyl, nrow = 2) Note above that we can define the desired number of rows for plotting with the nrow argument or number of columns with ncol and the other argument will be automatically determined. The ~ symbol is widely used in R. In these cases, it means that variables from aes() will be plotted as a function of variables after the tilde, i.e., for each combination of categories of these variables, a plot will be made with variables passed in aes(). In the case of facet_grid(), the organization of output will be a bit different. A grid will be made, as the function name itself says, where rows will concern one of the variables and column the other variable. It’s like a matrix of small graphs. cars_data %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg)) + facet_grid(am ~ cyl) 2.3.10 Titles, labels, themes and legends There are two ways to change titles and axis labels in ggplot2. You can choose ggtitle(\"graph title\"), xlab(\"x-axis label\"), ylab(\"y-axis label\"). Or you can use labs(). If using labs, you can change all these fields and others, like legend within the same function. Note, however, that the parameter controlling the legend title changes depending on the parameter within mapping = aes() from which the legend was generated. Normally, the legend is generated by either the colour, fill, size, shape, linetype and alpha parameters. These same parameters, depending on the case, should be passed within the labs() function to control the legend title, such as: labs(..., shape = \"Legend Title\"). cars_data %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, colour=factor(cyl))) + labs(title=&quot;Graph Title&quot;, x = &quot;X-axis Label&quot;, y = &quot;Y-axis Label&quot;, colour = &quot;Legend Title&quot;) # OR # cars_data %&gt;% # ggplot() + # geom_point(mapping=aes(x=wt, y=mpg, colour=factor(cyl))) + # ggtitle(&quot;Graph Title&quot;) + # xlab(&quot;X-axis Label&quot;) + # ylab(&quot;Y-axis Label&quot;) + # labs(colour=&quot;Legend Title&quot;) There are also specific functions that also control the legend name depending on the argument used to generate the legend inside aes() and also from which data type, whether continuous or discrete. We have the following cases: scale_GENERATOR_discrete(name=\"legend title\") scale_GENERATOR_continuous(name=\"legend title\") Thus, we have: scale_fill_discrete(name=\"legend title\"), scale_fill_continuous(name=\"legend title\"), scale_colour_discrete(name=\"legend title\"), scale_colour_continuous(name=\"legend title\"), and so on for other legend-generating arguments, like size, linetype, alpha and shape. # using txhousing dataset from ggplot2 package data(&quot;txhousing&quot;) library(lubridate) # to modify dates ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # Build a Date (first day of each month) and pick a few cities tx_subset &lt;- txhousing %&gt;% mutate(date = make_date(year, month, 1)) %&gt;% filter(city %in% c(&quot;Austin&quot;, &quot;Dallas&quot;, &quot;Houston&quot;)) # Line type by city ggplot(tx_subset, aes(x = date, y = median, linetype = city)) + geom_line() + scale_linetype_discrete(name = &quot;City&quot;) + labs(title = &quot;Median Home Price in Texas (by city)&quot;, x = &quot;Date&quot;, y = &quot;Median price (USD)&quot;) + theme_light() We can even have more than one mapping argument inside aes() and we can control legends of each one, adding one more layer to the graph: cars_data2 %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, size=hp, colour=factor(cyl))) + ggtitle(&quot;Cars Data&quot;) + xlab(&quot;Weight&quot;) + ylab(&quot;Miles per Gallon&quot;) + scale_size_continuous(name=&quot;Horsepower&quot;) + scale_colour_discrete(name=&quot;Cylinders&quot;) 2.3.11 Changing colors and color palette You must have noticed that in most graphs, ggplot2 uses the library’s default colors for plotting. If you’re not happy with the default color palette used by the package in mapping your variables, you can manually define these colors using another palette or other colors of your preference. The way to change the color palette used in a mapping argument inside aes() is through functions of type scale_GENERATOR_manual(), changing the values parameter. cars_data2 %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, size=hp, colour=factor(cyl))) + ggtitle(&quot;Cars Data&quot;) + xlab(&quot;Weight&quot;) + ylab(&quot;Miles per Gallon&quot;) + scale_size_continuous(name=&quot;Horsepower&quot;) + scale_colour_manual(values=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;)) Through these same functions of type scale_GENERATOR_manual(), we can also change category labels displayed in the legend using the labels argument. cars_data2 %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, size=hp, colour=factor(cyl))) + ggtitle(&quot;Cars Data&quot;) + xlab(&quot;Weight&quot;) + ylab(&quot;Miles per Gallon&quot;) + scale_size_continuous(name=&quot;Horsepower&quot;) + scale_colour_manual(values=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), labels=c(&quot;4 cyl&quot;, &quot;6 cyl&quot;, &quot;8 cyl&quot;)) As we mentioned several times up to this point in the course, in R there are several ways to do the same thing. Functions of type scale_GENERATOR_manual() also allow changing the legend title with the name argument: cars_data2 %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, size=hp, colour=factor(cyl))) + ggtitle(&quot;Cars Data&quot;) + xlab(&quot;Weight&quot;) + ylab(&quot;Miles per Gallon&quot;) + scale_size_continuous(name=&quot;Horsepower&quot;) + scale_colour_manual(values=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), labels=c(&quot;4 cyl&quot;, &quot;6 cyl&quot;, &quot;8 cyl&quot;), name=&quot;Cylinders&quot;) 2.3.12 Plot Area and Theme As we stated before, with ggplot2 it’s possible to modify practically all parameters of your graph. And there’s usually more than one way to make each of the changes. With the theme() function, it’s possible to control everything from the size of graph plotting elements, through label text size to the size of legend squares or “dots”. However, this will be research to be done by you. In this section we’ll bring just some ggplot2 functions that bring some pre-formatted themes: theme_gray(): gray background and white grid lines. It brings data forward to facilitate comparisons; theme_bw(): white background and gray grid lines. Recommended for presentations using projector; theme_linedraw(): white background and grid lines with different width. theme_light(): light gray grid lines and with presence of axes. Similar to theme_linedraw(); theme_dark(): same as theme_light() but with dark background. Makes thin colored lines stand out; theme_minimal(): minimalist theme without background; theme_classic(): classic theme without grid lines; theme_void(): empty theme, without background colors and grid. Recommended for unusual coordinate plots or drawings. cars_data %&gt;% ggplot() + geom_point(mapping=aes(x=wt, y=mpg, colour=factor(cyl))) + labs(title=&quot;Graph Title&quot;, x = &quot;X-axis Label&quot;, y = &quot;Y-axis Label&quot;, colour = &quot;Legend Title&quot;) + theme_bw() TIP: Strangely, ggplot2 always aligns the graph title to the left. You can center the title using precisely the theme() function, which we commented above, writing theme(plot.title = element_text(hjust=0.5)). 0.5 indicates that the title should be in the middle of the graph, according to specified horizontal alignment (hjust parameter). element_text() is a helper function that serves to control textual aspects like size (size) and other parameters like horizontal alignment itself. 2.3.13 Section References Ggplot themes gallery. (2020). DATANOVIA website. URL https://www.datanovia.com/en/blog/ggplot-themes-gallery/ Lin, A. Introduction to ggplot2. Slides. IDRE Statistical Consulting Group. URL https://stats.idre.ucla.edu/stat/data/intro_ggplot2_int/ggplot2_intro_interactive.html#(1) Lopes, J. G. (2019). The ggplot2 guide: how to make any type of graph in R. Blog: Exploring the Data Science Universe. 05, 2017. URL http://joseguilhermelopes.com.br/o-guia-do-ggplot2-como-fazer-qualquer-tipo-de-grafico-no-r/ Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: https://www.r4ds.co.nz. Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. 2016. URL https://ggplot2.tidyverse.org 2.3.14 Exercises Choose a dataset you’ve used recently at work and from which you’ve generated some graph in Excel or other software. Try to reproduce two or three graphs using the ggplot2 package. Don’t forget to look for help on the internet, especially on Stack Overflow and the package documentation, in addition to the handout. In the graphs from exercise 1, is there any aspect you’d like to improve? Research how to do it using ggplot2. Enhance your ggplot2 graph by means of the ggplotly(object_created_with_ggplot2) function from the plotly package. You can make your graph interactive and also build other different graphs with plotly. "],["m3.html", " 3 Module III 3.1 Accessing Relational Databases with dbplyr 3.2 Data Manipulation with Two-table verbs - dplyr 3.3 Geographic Data Analysis in R", " 3 Module III 3.1 Accessing Relational Databases with dbplyr 3.1.1 Introduction The content of this chapter was adapted from the dbplyr vignette and the article Databases using R by Edgar Ruiz, package author and member of RStudio. dbplyr allows combining the easy data manipulation grammar provided by dplyr with access to SQL relational databases without actually needing to use SQL commands. Using databases is inevitable for those whose work involves data analysis. At this point, as users of the R language, instinct leads us to adopt an approach with databases in the same way we would read a .txt or .csv data file: we would try to read all the data at once or parts of it until forming the entire dataset. The goal would be to “return” to the database as little as possible, so that our queries would extract as much data as possible. After that, we would spend several cycles analyzing that data saved in our computer’s memory. We would follow roughly this scheme: Source: Databases using R, Edgar Ruiz This approach has some problems: the volume of data we would have to work with would be very large. Therefore, we would spend some time thinking about how to minimize resource consumption and time to arrive at the subset of data we actually need to work with; to save resources, we would opt to directly use an external SQL client, process data as much as possible on the server side, extract what interests us and only then use R; we would need to know SQL in depth to make as many queries as possible using a “client” of SQL Server for example. We would save different scripts so we could repeat the queries again; What would be the best approach then? Source: Databases using R, Edgar Ruiz With dbplyr, the task of accessing relational databases would be EXTREMELY optimized, because: 1st) You don’t need to know SQL syntax to access data. Just knowing R and having a slight notion of SQL and you can already make a considerable number of data manipulations; 2nd) You will only need RStudio and no longer an external SQL client to make queries; 3rd) The code you would need in the first approach will be cut in half with the second 4th) Instead of spending hours thinking about which database you really need to import, we can analyze the data within the SQL server; 5th) Instead of using your computer’s memory, you’ll use the SQL server engine, because dbplyr together with dplyr will send queries to the server; Manipulating data with R commands (and even more with dplyr) is much easier than manipulating data with SQL commands. So, you can investigate and manipulate data much more easily just with R to only save the result on your computer at the end Before we start, you need to install and load the following packages: DBI and dbplyr. DBI is a backend that allows dplyr to communicate with various types of SQL databases using the same code. However, when installing and loading dbplyr, the DBI package will also be automatically loaded. # install.packages(&quot;dbplyr&quot;) library(dbplyr) In addition to dbplyr (and DBI), we’ll need a specific backend or driver for the type of SQL server we’re going to access. The most common are: RMySQL connects to MySQL and MariaDB; RPostgreSQL connects to Postgres and Redshift; RSQLite embeds an embedded SQLite database (very useful for training); odbc connects to various commercial databases (SQL Server, for example) using the open connectivity protocol; bigrquery connects to Google’s BigQuery. These backends are also implemented as R packages. For the examples in this handout, we’ll use RSQLite, because we’ll need to emulate a SQL-type database. 3.1.2 Connecting to a database To be able to work with a database together with dplyr, we must first establish a connection with this database, using DBI::dbConnect(). We thus create a connection object within R that will make the link in our RStudio session and the database. # install.packages(&quot;RSQLite&quot;) library(dplyr) con &lt;- DBI::dbConnect(drv = RSQLite::SQLite(), path = &quot;:memory:&quot;) The drv argument of DBI::dbConnect() can vary from database to database, but the first argument is always the driver of the type of database to which you will connect. It would be RSQLite::SQLite() for SQLite, RMySQL::MySQL() for MySQL, RPostgreSQL::PostgreSQL() for PostgreSQL, odbc::odbc() for SQL Server and bigrquery::bigquery() for Google BigQuery. SQLite only needs one more argument: the path to the database. In our case, we use the special string [:memory:] which will make SQLite build a temporary database in our computer’s memory. However, most databases don’t “live” in a file, but on a server. This means that in real life your code would be more like: con &lt;- DBI::dbConnect(RMySQL::MySQL(), host = &quot;database.company.com&quot;, user = &quot;username&quot;, password = rstudioapi::askForPassword(&quot;Database password&quot;) ) TIP: In real life, when creating the connection object with the actual relational server, you would see a connections tab in RStudio, with the respective schemas and/or tables present on the server. It’s like a Global Environment of the database: RStudio Connections Tab The temporary database we created earlier doesn’t have any data tables yet. Let’s start by copying a sample dataset. We’ll use the mtcars dataset that comes built-in with R, using the copy_to() function. Although this isn’t the most recommended way to put data into a database, it’s quite useful and easy to use in demonstrations: library(readr) # Using the built-in mtcars dataset cars_data &lt;- mtcars Once done, we can add the data to our fictional relational database: copy_to(con, cars_data, &quot;cars_db&quot;, temporary = FALSE, indexes = list( &quot;cyl&quot;, &quot;gear&quot; ) ) The copy_to() function has some additional arguments that allow us to provide indexes for the table. We then create indexes that will allow us to quickly process data by cyl and gear. Creating write indexes is a key point for good database performance when sending queries. However, this is beyond the scope of this course. Once we’ve copied the data to the server, we can reference (we’re not importing yet) this table in R using the tbl() function, which extracts the table called \"cars_db\" from the database. cars_db &lt;- tbl(con, &quot;cars_db&quot;) If we print the newly created reference, we’ll see it looks like a tibble, although it’s portrayed as a list in the Global Environment. cars_db ## # Source: table&lt;`cars_db`&gt; [?? x 11] ## # Database: sqlite 3.46.0 [] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ℹ more rows The only difference is the reference that the data is in a SQLite database. 3.1.3 Generating queries To interact with a database we usually use SQL - Structured Query Language. SQL is over 40 years old and is used in practically all existing databases. The goal of dbplyr is to automatically generate code in SQL so that we’re not forced to use it. However, dbplyr doesn’t do everything that SQL language does. It focuses on the declarative SELECT and derivatives, which we consider sufficient for the scope of this course. See how, most of the time, we don’t need to know anything about SQL and can continue using the dplyr verbs we’re already familiar with. cars_db %&gt;% select(mpg, cyl, hp) ## # Source: SQL [?? x 3] ## # Database: sqlite 3.46.0 [] ## mpg cyl hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 110 ## 2 21 6 110 ## 3 22.8 4 93 ## 4 21.4 6 110 ## 5 18.7 8 175 ## 6 18.1 6 105 ## 7 14.3 8 245 ## 8 24.4 4 62 ## 9 22.8 4 95 ## 10 19.2 6 123 ## # ℹ more rows cars_db %&gt;% filter(mpg &gt; 20) ## # Source: SQL [?? x 11] ## # Database: sqlite 3.46.0 [] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 6 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 7 32.4 4 78.7 66 4.08 2.2 19.5 1 1 4 1 ## 8 30.4 4 75.7 52 4.93 1.62 18.5 1 1 4 2 ## 9 33.9 4 71.1 65 4.22 1.84 19.9 1 1 4 1 ## 10 21.5 4 120. 97 3.7 2.46 20.0 1 0 3 1 ## # ℹ more rows cars_db %&gt;% group_by(cyl) %&gt;% summarise(avg_mpg = mean(mpg, na.rm = TRUE)) ## # Source: SQL [3 x 2] ## # Database: sqlite 3.46.0 [] ## cyl avg_mpg ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 However, in the long run it’s highly recommended that you learn at least the basics of SQL. SQL is a quite important skill for any data scientist or people who deal with data routinely. The most important difference between ordinary dataframes and queries to remote databases is that our R code is translated to SQL language and executed in the database, not in R. When working with databases, dplyr tries to be as lazy as possible. dplyr relies on a concept widely used in R, which is lazy evaluation: It never brings data to R unless we explicitly request it to do so; It “delays” doing any task until the last moment: it collects all commands and sends to the database in a single step. See the following example: by_cyl_db &lt;- cars_db %&gt;% group_by(cyl) %&gt;% summarise( avg_mpg = mean(mpg, na.rm=TRUE), n = n() ) %&gt;% arrange(desc(avg_mpg)) %&gt;% filter(n &gt; 5) It’s surprising what we’re going to say now, but all this code doesn’t touch the database at any time; not until we request it, for example by doing a printing of the created object by_cyl_db. Only then does dplyr generate the SQL code and request the results from the database on the SQL server. Still, it tries to minimize what will be printed, bringing only a few lines and not everything. See: by_cyl_db ## # Source: SQL [3 x 3] ## # Database: sqlite 3.46.0 [] ## # Ordered by: desc(avg_mpg) ## cyl avg_mpg n ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 4 26.7 11 ## 2 6 19.7 7 ## 3 8 15.1 14 Behind the scenes, dbplyr/dplyr is translating the code in R to SQL code. If you want to see (and learn) the SQL code being sent to the server, use show_query(): by_cyl_db %&gt;% show_query() ## &lt;SQL&gt; ## SELECT `cyl`, AVG(`mpg`) AS `avg_mpg`, COUNT(*) AS `n` ## FROM `cars_db` ## GROUP BY `cyl` ## HAVING (COUNT(*) &gt; 5.0) ## ORDER BY `avg_mpg` DESC For those more familiar with SQL, the code above probably wouldn’t be what you would write, but it accomplishes the mission. See vignette(\"SQL-translation\"). Even with dbplyr/dplyr, we’ll still do some iterations and attempts until we discover what we’ll really need from the data. However, we’ll do it much faster. Once we know exactly our goal, we can use collect() to bring all the data into a (local) tibble on our machine: by_cyl_final &lt;- by_cyl_db %&gt;% collect() by_cyl_final ## # A tibble: 3 × 3 ## cyl avg_mpg n ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 4 26.7 11 ## 2 6 19.7 7 ## 3 8 15.1 14 collect() requires the database to work and therefore the operation may take some time to complete. On the other hand, dbplyr tries to prevent you from accidentally making computationally expensive queries: There’s usually no way to determine how many rows a query will return until we actually execute it. Unlike when working with databases on our PC, the nrow() command always returns NA when firing against relational databases; Since we can’t find the last few rows without executing the query of all data, we can’t use tail(), which prints the \\(n\\) last rows of a tibble or dataframe. nrow(by_cyl_db) ## [1] NA tail(by_cyl_db) ## Error in `tail()`: ## ! `tail()` is not supported on database backends. 3.1.4 Section References Wickham, H.; Ruiz, E. (2019). dbplyr: A ‘dplyr’ Back End for Databases. R package version 1.4.0. URL https://CRAN.R-project.org/package=dbplyr. ____. (2020). dbplyr vignette: Introduction. URL http://dbplyr.tidyverse.org. Ruiz, E. (2017). Databases using R. RViews-RStudio. May 05, 2017. Available at: https://rviews.rstudio.com/2017/05/17/databases-using-r/ 3.1.5 Exercises Practice using the database connection skills learned with a local SQLite database. Create your own sample dataset, upload it to the database, and practice writing queries using dplyr verbs. Explore the SQL code generated by dbplyr for different operations. Use show_query() to see how your R code is translated to SQL. 3.2 Data Manipulation with Two-table verbs - dplyr Data analysis, most of the time, involves more than one database. In practice, they are databases from different sources that contribute to reaching a final result. Thus, we need flexible tools to combine them. In the dplyr package, there are three families of verbs that work with two tables at once: mutating joins, which add new variables to a table from matching rows in another; filtering joins, which filter observations from a table if these observations match an observation in another table; set operations, which combine observations in datasets if they are elements of the informed set. These items assume your data is in tidy data format, i.e., rows are observations and columns are variables. All two-table verbs (or two-table functions) work similarly: the first two arguments are x and y and provide the two tables we want to compare and combine. The output will always be a new table with the same object type as x. 3.2.1 Mutating joins Mutating joins allow us to combine variables from multiple tables. We’ll use some datasets from the nycflights13 package which includes data from 336,776 flights (tibble flights), weather conditions (tibble weather) and aircraft (tibble planes) that landed and took off from 3 airports (tibble airports) in New York in 2013. The data comes from the US Bureau of Transportation Statistics. Initially we’ll use the flights dataset. Let’s separate some columns from the original tibble into another. Then we’ll try to join the two based on the airline name. library(&quot;nycflights13&quot;) library(dplyr) # Drop unimportant variables so it&#39;s easier to understand the join results. flights2 &lt;- flights %&gt;% select(year:day, hour, origin, dest, tailnum, carrier) flights2 %&gt;% left_join(airlines) ## # A tibble: 336,776 × 9 ## year month day hour origin dest tailnum carrier name ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA United Air Lines Inc. ## 2 2013 1 1 5 LGA IAH N24211 UA United Air Lines Inc. ## 3 2013 1 1 5 JFK MIA N619AA AA American Airlines Inc. ## 4 2013 1 1 5 JFK BQN N804JB B6 JetBlue Airways ## 5 2013 1 1 6 LGA ATL N668DN DL Delta Air Lines Inc. ## 6 2013 1 1 5 EWR ORD N39463 UA United Air Lines Inc. ## 7 2013 1 1 6 EWR FLL N516JB B6 JetBlue Airways ## 8 2013 1 1 6 LGA IAD N829AS EV ExpressJet Airlines Inc. ## 9 2013 1 1 6 JFK MCO N593JB B6 JetBlue Airways ## 10 2013 1 1 6 LGA ORD N3ALAA AA American Airlines Inc. ## # ℹ 336,766 more rows 3.2.1.1 Controlling how tables match in mutating joins Along with the x and y arguments, each mutating join also receives a by argument which is used as an index to match between tables. There are several ways to specify this argument. Let’s see examples of how to specify the by parameter, using some tables from nycflights13. 1st way) NULL: the default. dplyr will use all variables that appear in both tables. We call this a natural join. In the following example, the flights and weather tables will be “joined” based on common variables: year, month, day, hour and origin. flights2 %&gt;% left_join(weather) ## Joining with `by = join_by(year, month, day, hour, origin)` ## # A tibble: 336,776 × 18 ## year month day hour origin dest tailnum carrier temp dewp humid wind_dir wind_speed wind_gust precip ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA 39.0 28.0 64.4 260 12.7 NA 0 ## 2 2013 1 1 5 LGA IAH N24211 UA 39.9 25.0 54.8 250 15.0 21.9 0 ## 3 2013 1 1 5 JFK MIA N619AA AA 39.0 27.0 61.6 260 15.0 NA 0 ## 4 2013 1 1 5 JFK BQN N804JB B6 39.0 27.0 61.6 260 15.0 NA 0 ## 5 2013 1 1 6 LGA ATL N668DN DL 39.9 25.0 54.8 260 16.1 23.0 0 ## 6 2013 1 1 5 EWR ORD N39463 UA 39.0 28.0 64.4 260 12.7 NA 0 ## 7 2013 1 1 6 EWR FLL N516JB B6 37.9 28.0 67.2 240 11.5 NA 0 ## 8 2013 1 1 6 LGA IAD N829AS EV 39.9 25.0 54.8 260 16.1 23.0 0 ## 9 2013 1 1 6 JFK MCO N593JB B6 37.9 27.0 64.3 260 13.8 NA 0 ## 10 2013 1 1 6 LGA ORD N3ALAA AA 39.9 25.0 54.8 260 16.1 23.0 0 ## # ℹ 336,766 more rows ## # ℹ 3 more variables: pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt; 2nd way) by = \"var1\" or by = c(\"var1\", \"var2\", \"var3\"): a character vector. Operates as if it were a natural join, but uses only some of the common variables. For example, flights and planes have a year variable, but they mean different things in each tibble/dataframe. So, we want to specify a column we know means the same thing in both tibbles and can serve as an index for matching. Let’s use tailnum which is the plane’s (tail) number. flights2 %&gt;% left_join(planes, by = &quot;tailnum&quot;) ## # A tibble: 336,776 × 16 ## year.x month day hour origin dest tailnum carrier year.y type manufacturer model engines seats speed engine ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA 1999 Fixed… BOEING 737-… 2 149 NA Turbo… ## 2 2013 1 1 5 LGA IAH N24211 UA 1998 Fixed… BOEING 737-… 2 149 NA Turbo… ## 3 2013 1 1 5 JFK MIA N619AA AA 1990 Fixed… BOEING 757-… 2 178 NA Turbo… ## 4 2013 1 1 5 JFK BQN N804JB B6 2012 Fixed… AIRBUS A320… 2 200 NA Turbo… ## 5 2013 1 1 6 LGA ATL N668DN DL 1991 Fixed… BOEING 757-… 2 178 NA Turbo… ## 6 2013 1 1 5 EWR ORD N39463 UA 2012 Fixed… BOEING 737-… 2 191 NA Turbo… ## 7 2013 1 1 6 EWR FLL N516JB B6 2000 Fixed… AIRBUS INDU… A320… 2 200 NA Turbo… ## 8 2013 1 1 6 LGA IAD N829AS EV 1998 Fixed… CANADAIR CL-6… 2 55 NA Turbo… ## 9 2013 1 1 6 JFK MCO N593JB B6 2004 Fixed… AIRBUS A320… 2 200 NA Turbo… ## 10 2013 1 1 6 LGA ORD N3ALAA AA NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA &lt;NA&gt; ## # ℹ 336,766 more rows Note that when joining all columns from both tibbles, dplyr adds a suffix to the second year variable. 3rd way) by = c(\"var1\" = \"var3\"): a named character vector. This will match variable var1 in table x with variable var3 in table y. Variables from source table x will be used in the output. Each flight has an origin and destination airport. So we need to specify which of these variables from the flights dataset we want to match with the faa column from the airports dataset. flights2 %&gt;% left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) ## # A tibble: 336,776 × 15 ## year month day hour origin dest tailnum carrier name lat lon alt tz dst tzone ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA George Bush Intercontin… 30.0 -95.3 97 -6 A Amer… ## 2 2013 1 1 5 LGA IAH N24211 UA George Bush Intercontin… 30.0 -95.3 97 -6 A Amer… ## 3 2013 1 1 5 JFK MIA N619AA AA Miami Intl 25.8 -80.3 8 -5 A Amer… ## 4 2013 1 1 5 JFK BQN N804JB B6 &lt;NA&gt; NA NA NA NA &lt;NA&gt; &lt;NA&gt; ## 5 2013 1 1 6 LGA ATL N668DN DL Hartsfield Jackson Atla… 33.6 -84.4 1026 -5 A Amer… ## 6 2013 1 1 5 EWR ORD N39463 UA Chicago Ohare Intl 42.0 -87.9 668 -6 A Amer… ## 7 2013 1 1 6 EWR FLL N516JB B6 Fort Lauderdale Hollywo… 26.1 -80.2 9 -5 A Amer… ## 8 2013 1 1 6 LGA IAD N829AS EV Washington Dulles Intl 38.9 -77.5 313 -5 A Amer… ## 9 2013 1 1 6 JFK MCO N593JB B6 Orlando Intl 28.4 -81.3 96 -5 A Amer… ## 10 2013 1 1 6 LGA ORD N3ALAA AA Chicago Ohare Intl 42.0 -87.9 668 -6 A Amer… ## # ℹ 336,766 more rows flights2 %&gt;% left_join(airports, c(&quot;origin&quot; = &quot;faa&quot;)) ## # A tibble: 336,776 × 15 ## year month day hour origin dest tailnum carrier name lat lon alt tz dst tzone ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA Newark Liberty Intl 40.7 -74.2 18 -5 A America/N… ## 2 2013 1 1 5 LGA IAH N24211 UA La Guardia 40.8 -73.9 22 -5 A America/N… ## 3 2013 1 1 5 JFK MIA N619AA AA John F Kennedy Intl 40.6 -73.8 13 -5 A America/N… ## 4 2013 1 1 5 JFK BQN N804JB B6 John F Kennedy Intl 40.6 -73.8 13 -5 A America/N… ## 5 2013 1 1 6 LGA ATL N668DN DL La Guardia 40.8 -73.9 22 -5 A America/N… ## 6 2013 1 1 5 EWR ORD N39463 UA Newark Liberty Intl 40.7 -74.2 18 -5 A America/N… ## 7 2013 1 1 6 EWR FLL N516JB B6 Newark Liberty Intl 40.7 -74.2 18 -5 A America/N… ## 8 2013 1 1 6 LGA IAD N829AS EV La Guardia 40.8 -73.9 22 -5 A America/N… ## 9 2013 1 1 6 JFK MCO N593JB B6 John F Kennedy Intl 40.6 -73.8 13 -5 A America/N… ## 10 2013 1 1 6 LGA ORD N3ALAA AA La Guardia 40.8 -73.9 22 -5 A America/N… ## # ℹ 336,766 more rows 3.2.1.2 Types of mutating joins There are 4 types of mutating join, which differ by behavior in rows where no matching occurs between databases. Let’s create two dataframes and then we’ll see examples of each case. (df1 &lt;- data.frame(x = c(1, 2), y = 2:1)) ## x y ## 1 1 2 ## 2 2 1 (df2 &lt;- data.frame(x = c(1, 3), a = 10, b = &quot;a&quot;)) ## x a b ## 1 1 10 a ## 2 3 10 a inner_join(x, y): includes only observations that have correspondence in both x and y (i.e., equal rows in dataframes). df1 %&gt;% inner_join(df2) ## Joining with `by = join_by(x)` ## x y a b ## 1 1 2 10 a Note that the by argument was omitted. Thus, the function’s behavior was the default. Column x was used as an index to join the two data frames. Equal rows for variable x in both dataframes are brought in full (i.e., all columns are presented). left_join(x, y): includes all observations in x, regardless of whether there’s matching between tables. This is the most used type of join, because it guarantees we won’t lose any information from our primary table x. df1 %&gt;% left_join(df2) ## Joining with `by = join_by(x)` ## x y a b ## 1 1 2 10 a ## 2 2 1 NA &lt;NA&gt; right_join(x, y): includes all observations from table y. It’s equivalent to left_join(**y**, **x**), but variable ordering will be different in the latter case: df1 %&gt;% right_join(df2) ## Joining with `by = join_by(x)` ## x y a b ## 1 1 2 10 a ## 2 3 NA 10 a df2 %&gt;% left_join(df1) ## Joining with `by = join_by(x)` ## x a b y ## 1 1 10 a 2 ## 2 3 10 a NA full_join(): includes all observations from table x and y: df1 %&gt;% full_join(df2) ## Joining with `by = join_by(x)` ## x y a b ## 1 1 2 10 a ## 2 2 1 NA &lt;NA&gt; ## 3 3 NA 10 a The left, right and full joins are collectively known as outer joins. When a row from one table has no correspondence in the other table, in an outer join, new variables are filled with missing values (NA). Although mutating joins exist to add new variables, in some cases they can generate new observations. If a match isn’t unique, a join will add rows for all possible combinations (Cartesian product) of matching observations. This is an important observation, because often when performing a join between two tables, we don’t understand why the table resulting from the join has more observations than the two original tables. df1 &lt;- data.frame(x = c(1, 1, 2), y = 1:3) df2 &lt;- data.frame(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) df1 %&gt;% left_join(df2) ## Joining with `by = join_by(x)` ## Warning in left_join(., df2): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. ## x y z ## 1 1 1 a ## 2 1 1 b ## 3 1 2 a ## 4 1 2 b ## 5 2 3 a 3.2.2 Filtering joins Filtering joins “match” observations in the same way as mutating joins, but affect observations themselves and not variables. There are two types of filtering joins: semi_join() KEEPS all observations in x that have correspondence in y; anti_join() REMOVES all observations in x that have correspondence in y. These joins are very useful for identifying “mismatches” between tables. For example, there are several flights in the flights dataset that don’t have matches regarding tailnum in the planes dataset: flights %&gt;% anti_join(planes, by = &quot;tailnum&quot;) %&gt;% count(tailnum, sort = TRUE) ## # A tibble: 722 × 2 ## tailnum n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 2512 ## 2 N725MQ 575 ## 3 N722MQ 513 ## 4 N723MQ 507 ## 5 N713MQ 483 ## 6 N735MQ 396 ## 7 N0EGMQ 371 ## 8 N534MQ 364 ## 9 N542MQ 363 ## 10 N531MQ 349 ## # ℹ 712 more rows If you’re concerned about which observations our join will match, it’s suggested to start with a semi_join() or anti_join() for the following reason: these joins never duplicate observations, they only remove or keep them in the same number. df1 &lt;- data.frame(x = c(1, 1, 3, 4), y = 1:4) df2 &lt;- data.frame(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) # Four rows to start with: df1 %&gt;% nrow() ## [1] 4 # And we get four rows after the join df1 %&gt;% inner_join(df2, by = &quot;x&quot;) %&gt;% nrow() ## Warning in inner_join(., df2, by = &quot;x&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. ## [1] 4 # But only two rows actually match df1 %&gt;% semi_join(df2, by = &quot;x&quot;) %&gt;% nrow() ## [1] 2 Finally, it’s worth mentioning functions that would be useful if you had to work with 3 or more tables. Read about purrr::reduce() or Reduce(), as described in “Advanced R”, to iteratively combine and expand your knowledge of two-table verbs to handle a larger number of tables. The content of this chapter was adapted from the two-table verbs vignette, available at http://dplyr.tidyverse.org/articles/two-table.html. 3.2.3 Section References Wickham H.; François, R.; Henry, L.; Müller K. (2019). dplyr: A Grammar of Data Manipulation. R package version 0.8.1. URL https://CRAN.R-project.org/package=dplyr. Wickham H.; François, R.; Henry, L.; Müller K. (2020). dplyr vignette: Two-table. Article. Available at: http://dplyr.tidyverse.org/articles/two-table.html. Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: https://www.r4ds.co.nz. 3.2.4 Exercises Try to replicate each of the joins presented in this section using the nycflights13 datasets. Practice joining flights with different tables like airports, airlines, weather, and planes. Create your own small datasets and practice all four types of joins (inner_join, left_join, right_join, full_join). Pay attention to how each handles non-matching rows. Use anti_join() to find flights in the flights dataset that don’t have weather information in the weather dataset. 3.3 Geographic Data Analysis in R 3.3.1 Introduction In recent decades there has been a real revolution in geocomputation techniques. Thanks to this great advance, geographic data analysis is no longer restricted to those who have access to expensive hardware and software. In a way, we can say that R also contributed to this advance. Although the language had some limitations regarding geocomputation in the early years of language development, recently several R packages have taken geocomputation to a new level, especially regarding reproducibility. While software based on Geographic Information Systems (GIS), which has Geography as its base discipline and focus on graphical interfaces, leaves something to be desired in the reproducibility of generated maps, R, which is based on Statistics and Computing through command line and programming, makes geographic data analysis much more fluid and capable of reproduction by other users and developers. In this section, we’ll present some of the main packages and techniques used for map production using R. 3.3.1.1 Geographic data models: vector vs raster In the field of geocomputation, we need to know how to differentiate the two main types of geographic data: vector and raster. Geographic data in vector form uses points, lines and polygons to represent a map. In this case, object edges (e.g. States, Municipalities, Countries) are well defined. Figure 3.1: Example of vector plot Data in raster format divides a map’s surface into cells of constant sizes. Datasets in raster format are commonly used to generate maps as background images (background). Raster models have been used practically since the origin of Remote Sensing devices and satellites. In this course, we’ll focus on geographic data models in vector, which is the predominant data model in Social Sciences. This is because spatial arrangements produced by humans tend to have discrete and well-defined boundaries. The raster model is more used in environmental or earth sciences due to the use of data from remote sensing. Now that we know the conceptual differences between the main geographic data models, let’s get practical. 3.3.2 Map Production in R 3.3.2.1 Shapefiles Shapefiles are files that follow the geographic data model in vector, containing graphic elements in the format of point, line and/or polygons that can be worked together with geographic coordinates to describe a specific phenomenon, such as population size, disease incidence, unemployment rates, etc. From this information, it’s possible to construct a map. A shapefile normally contains three main files .shp, .shx, .dbf. There are several places from which you can obtain shapefiles for map making. If your goal is to obtain shapefiles for US territorial boundaries, you can get them from these sources: US Census Bureau - TIGER/Line Shapefiles: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html Natural Earth Data: https://www.naturalearthdata.com/downloads/ GADM: https://gadm.org/download_country_v3.html TIP: The spData package already includes geographic data for US states, which makes our work easier for educational purposes. We’ll focus on demonstrating how to work with shapefiles using the spData package that already has ready-made data. For any other data source, procedures will be practically the same. 3.3.2.2 Map of US States 3.3.2.2.1 Obtaining and reading the file Let’s use the spData package which already contains the territorial mesh of US states. We’ll also need the sf package to work with spatial data. # Loading necessary packages library(sf) library(spData) library(dplyr) library(ggplot2) # Loading US states data data(&quot;us_states&quot;) # Converting to sf object (simple features) shp_us_states &lt;- st_as_sf(us_states) # Viewing the data structure head(shp_us_states) ## Simple feature collection with 6 features and 6 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -114.8136 ymin: 24.55868 xmax: -71.78699 ymax: 42.04964 ## Geodetic CRS: NAD83 ## GEOID NAME REGION AREA total_pop_10 total_pop_15 geometry ## 1 01 Alabama South 133709.27 [km^2] 4712651 4830620 MULTIPOLYGON (((-88.20006 3... ## 2 04 Arizona West 295281.25 [km^2] 6246816 6641928 MULTIPOLYGON (((-114.7196 3... ## 3 08 Colorado West 269573.06 [km^2] 4887061 5278906 MULTIPOLYGON (((-109.0501 4... ## 4 09 Connecticut Norteast 12976.59 [km^2] 3545837 3593222 MULTIPOLYGON (((-73.48731 4... ## 5 12 Florida South 151052.01 [km^2] 18511620 19645772 MULTIPOLYGON (((-81.81169 2... ## 6 13 Georgia South 152725.21 [km^2] 9468815 10006693 MULTIPOLYGON (((-85.60516 3... Note that in addition to state names, region they belong to (REGION), area, total population and other variables, this special dataframe has a column called geom. This column has the vector geometric elements for map making in the vector data model mentioned earlier. 3.3.2.2.2 Plotting the Map Using ggplot2 (Recommended Method) The most reliable way to create maps in R is using ggplot2 with geom_sf(). This approach handles complex geometries better and produces professional-looking maps: ggplot(data = shp_us_states) + geom_sf(fill = &quot;lightblue&quot;, color = &quot;white&quot;, size = 0.3) + labs(title = &quot;United States - State Boundaries&quot;) + theme_minimal() Very simple to make maps in R, right? Alternative: Using base R plot() If you prefer base R graphics, here’s how to do it with proper configuration: # This requires proper graphics device setup par(mar = c(0, 0, 2, 0)) plot(st_geometry(shp_us_states), main = &quot;United States - State Boundaries&quot;, col = &quot;lightblue&quot;, border = &quot;white&quot;, lwd = 0.5) 3.3.2.2.3 Adding data to the map Normally, when doing geographic analyses, our goal is to represent some phenomenon occurring in the territory, such as unemployment rate behavior by state. Let’s create simulated unemployment rate data for US states in the year 2020: set.seed(123) # for reproducibility # Creating unemployment rate data unemployment_data &lt;- data.frame( NAME = shp_us_states$NAME, unemployment_rate = round(runif(nrow(shp_us_states), min = 3.5, max = 8.5), 1) ) head(unemployment_data) ## NAME unemployment_rate ## 1 Alabama 4.9 ## 2 Arizona 7.4 ## 3 Colorado 5.5 ## 4 Connecticut 7.9 ## 5 Florida 8.2 ## 6 Georgia 3.7 Now we must join this data to the dataframe containing the boundaries of US states. Let’s use the left_join() function from dplyr. We’ll join the tables based on the column containing state names. shape_data_join &lt;- left_join(shp_us_states, unemployment_data, by = &quot;NAME&quot;) # Check the result head(shape_data_join[, c(&quot;NAME&quot;, &quot;REGION&quot;, &quot;unemployment_rate&quot;)]) ## Simple feature collection with 6 features and 3 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -114.8136 ymin: 24.55868 xmax: -71.78699 ymax: 42.04964 ## Geodetic CRS: NAD83 ## NAME REGION unemployment_rate geometry ## 1 Alabama South 4.9 MULTIPOLYGON (((-88.20006 3... ## 2 Arizona West 7.4 MULTIPOLYGON (((-114.7196 3... ## 3 Colorado West 5.5 MULTIPOLYGON (((-109.0501 4... ## 4 Connecticut Norteast 7.9 MULTIPOLYGON (((-73.48731 4... ## 5 Florida South 8.2 MULTIPOLYGON (((-81.81169 2... ## 6 Georgia South 3.7 MULTIPOLYGON (((-85.60516 3... 3.3.2.2.4 Creating a Choropleth Map with ggplot2 Now let’s create a professional choropleth map showing unemployment rates: ggplot(data = shape_data_join) + geom_sf(aes(fill = unemployment_rate), color = &quot;white&quot;, size = 0.2) + scale_fill_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;, name = &quot;Unemployment\\nRate (%)&quot;, breaks = seq(3, 9, by = 1)) + labs(title = &quot;Unemployment Rate by State, 2020&quot;, subtitle = &quot;Simulated data for educational purposes&quot;, caption = &quot;Source: Simulated data&quot;) + theme_minimal() + theme(legend.position = &quot;right&quot;, plot.title = element_text(face = &quot;bold&quot;, size = 14), plot.subtitle = element_text(size = 10), panel.grid = element_blank()) Alternative visualization with discrete colors: library(RColorBrewer) # Create discrete categories shape_data_join &lt;- shape_data_join %&gt;% mutate(unemployment_category = cut(unemployment_rate, breaks = seq(3, 9, by = 1), labels = c(&quot;3-4%&quot;, &quot;4-5%&quot;, &quot;5-6%&quot;, &quot;6-7%&quot;, &quot;7-8%&quot;, &quot;8-9%&quot;), include.lowest = TRUE)) ggplot(data = shape_data_join) + geom_sf(aes(fill = unemployment_category), color = &quot;white&quot;, size = 0.2) + scale_fill_brewer(palette = &quot;YlOrRd&quot;, name = &quot;Unemployment\\nRate&quot;, na.value = &quot;grey90&quot;) + labs(title = &quot;Unemployment Rate by State, 2020&quot;, subtitle = &quot;Simulated data for educational purposes&quot;) + theme_minimal() + theme(legend.position = &quot;right&quot;, plot.title = element_text(face = &quot;bold&quot;, size = 14), panel.grid = element_blank()) TIP: With ggplot2 and geom_sf(), we can use all the familiar ggplot2 functions to customize our maps! 3.3.2.2.5 Adding more data to the map Let’s add GDP growth data and create a more complex visualization: set.seed(456) # Creating GDP growth data gdp_growth_data &lt;- data.frame( NAME = shp_us_states$NAME, gdp_growth = round(runif(nrow(shp_us_states), min = -3, max = 5), 1) ) # Join with existing data shape_data_join2 &lt;- left_join(shape_data_join, gdp_growth_data, by = &quot;NAME&quot;) head(shape_data_join2[, c(&quot;NAME&quot;, &quot;unemployment_rate&quot;, &quot;gdp_growth&quot;)]) ## Simple feature collection with 6 features and 3 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -114.8136 ymin: 24.55868 xmax: -71.78699 ymax: 42.04964 ## Geodetic CRS: NAD83 ## NAME unemployment_rate gdp_growth geometry ## 1 Alabama 4.9 -2.3 MULTIPOLYGON (((-88.20006 3... ## 2 Arizona 7.4 -1.3 MULTIPOLYGON (((-114.7196 3... ## 3 Colorado 5.5 2.9 MULTIPOLYGON (((-109.0501 4... ## 4 Connecticut 7.9 3.8 MULTIPOLYGON (((-73.48731 4... ## 5 Florida 8.2 3.3 MULTIPOLYGON (((-81.81169 2... ## 6 Georgia 3.7 -0.3 MULTIPOLYGON (((-85.60516 3... Now let’s create a bivariate map showing both unemployment and GDP growth: # Get state centroids for bubble plot state_centers &lt;- suppressWarnings(st_centroid(shape_data_join2)) # Create the base map with unemployment rate ggplot(data = shape_data_join2) + geom_sf(aes(fill = unemployment_rate), color = &quot;white&quot;, size = 0.2) + scale_fill_viridis_c(option = &quot;plasma&quot;, name = &quot;Unemployment\\nRate (%)&quot;, direction = -1) + # Add bubbles for GDP growth geom_sf(data = state_centers, aes(size = abs(gdp_growth), color = gdp_growth &gt; 0), alpha = 0.6, show.legend = &quot;point&quot;) + scale_size_continuous(name = &quot;GDP Growth\\n(absolute %)&quot;, range = c(1, 8)) + scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;), labels = c(&quot;Negative&quot;, &quot;Positive&quot;), name = &quot;GDP Growth\\nDirection&quot;) + labs(title = &quot;Unemployment Rate and GDP Growth by State, 2020&quot;, subtitle = &quot;Fill color shows unemployment rate; bubble size shows GDP growth magnitude&quot;, caption = &quot;Source: Simulated data for educational purposes&quot;) + theme_minimal() + theme(legend.position = &quot;right&quot;, plot.title = element_text(face = &quot;bold&quot;, size = 14), panel.grid = element_blank()) 3.3.2.2.6 Focusing on a specific region: Florida and neighboring states As an additional example, let’s create a map focused on Florida and neighboring states. This is particularly relevant since this course is being taught at the University of North Florida (UNF) in Jacksonville. # Selecting Florida and neighboring states southeast_states &lt;- c(&quot;Florida&quot;, &quot;Georgia&quot;, &quot;Alabama&quot;, &quot;South Carolina&quot;) shape_southeast &lt;- shape_data_join2 %&gt;% filter(NAME %in% southeast_states) # Creating regional map with ggplot2 ggplot(data = shape_southeast) + geom_sf(aes(fill = unemployment_rate), color = &quot;black&quot;, size = 0.5) + geom_sf_text(aes(label = NAME), size = 3.5, fontface = &quot;bold&quot;, check_overlap = TRUE) + scale_fill_gradient(low = &quot;lightblue&quot;, high = &quot;darkblue&quot;, name = &quot;Unemployment\\nRate (%)&quot;) + labs(title = &quot;Unemployment in Southeast US States, 2020&quot;, subtitle = &quot;Focus: Florida and neighboring states&quot;, caption = &quot;Data: Simulated for educational purposes&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, plot.title = element_text(face = &quot;bold&quot;), panel.grid = element_blank()) Adding UNF marker to Florida map: # Get only Florida florida &lt;- shape_southeast %&gt;% filter(NAME == &quot;Florida&quot;) # Create UNF location point unf_location &lt;- st_sfc(st_point(c(-81.6557, 30.3322)), crs = 4326) unf_location &lt;- st_sf(name = &quot;UNF&quot;, geometry = unf_location) ggplot() + geom_sf(data = florida, aes(fill = unemployment_rate), color = &quot;black&quot;, size = 0.5) + geom_sf(data = unf_location, color = &quot;red&quot;, size = 4, shape = 17) + geom_sf_text(data = unf_location, aes(label = &quot;Jacksonville\\n(UNF)&quot;), nudge_x = 1, nudge_y = 0.3, size = 3.5, fontface = &quot;bold&quot;) + scale_fill_gradient(low = &quot;lightblue&quot;, high = &quot;darkblue&quot;, name = &quot;Unemployment\\nRate (%)&quot;) + labs(title = &quot;Florida Unemployment Rate, 2020&quot;, subtitle = &quot;University of North Florida location marked&quot;, caption = &quot;Data: Simulated for educational purposes&quot;) + theme_minimal() + theme(legend.position = &quot;right&quot;, plot.title = element_text(face = &quot;bold&quot;), panel.grid = element_blank()) 3.3.2.2.7 Creating interactive maps with leaflet For interactive maps that can be shared online or embedded in websites, leaflet is an excellent choice: library(leaflet) # Create a simple interactive map centered on Jacksonville, FL leaflet() %&gt;% addTiles() %&gt;% # Add default OpenStreetMap tiles setView(lng = -81.6557, lat = 30.3322, zoom = 11) %&gt;% addMarkers(lng = -81.6557, lat = 30.3322, popup = &quot;&lt;b&gt;University of North Florida&lt;/b&gt;&lt;br/&gt;Jacksonville, FL&quot;) %&gt;% addCircleMarkers(lng = -81.6557, lat = 30.3322, radius = 50, color = &quot;blue&quot;, fillOpacity = 0.2, popup = &quot;UNF Campus Area&quot;) We can also create an interactive choropleth map showing our unemployment data: library(leaflet) # For leaflet, we need to transform to WGS84 (EPSG:4326) shape_leaflet &lt;- st_transform(shape_data_join2, 4326) # Create color palette pal &lt;- colorNumeric(palette = &quot;YlOrRd&quot;, domain = shape_leaflet$unemployment_rate) # Create interactive map leaflet(shape_leaflet) %&gt;% addTiles() %&gt;% addPolygons( fillColor = ~pal(unemployment_rate), weight = 1, opacity = 1, color = &quot;white&quot;, fillOpacity = 0.7, highlightOptions = highlightOptions( weight = 3, color = &quot;#666&quot;, fillOpacity = 0.9, bringToFront = TRUE ), label = ~paste0(NAME, &quot;: &quot;, unemployment_rate, &quot;%&quot;), popup = ~paste0(&quot;&lt;strong&gt;&quot;, NAME, &quot;&lt;/strong&gt;&lt;br/&gt;&quot;, &quot;Unemployment: &quot;, unemployment_rate, &quot;%&lt;br/&gt;&quot;, &quot;GDP Growth: &quot;, gdp_growth, &quot;%&quot;) ) %&gt;% addLegend(pal = pal, values = ~unemployment_rate, opacity = 0.7, title = &quot;Unemployment Rate (%)&quot;, position = &quot;bottomright&quot;) TIP: Interactive maps created with leaflet are great for presentations and can be easily embedded in websites or R Markdown HTML outputs! 3.3.2.2.8 Other packages for map generation Besides the methods we’ve shown, there are several other alternatives in the R ecosystem for generating maps: ggmap: Combines ggplot2 with map tiles from Google Maps, OpenStreetMap, and others plotly: Can convert ggplot2 maps to interactive versions using ggplotly() mapview: Quick interactive viewing of spatial data tmap: Thematic maps with a grammar similar to ggplot2 (though it may have compatibility issues in some environments) 3.3.3 Exporting geographic data 3.3.3.1 Writing vector data files Just as in reading vector data, the recommended package for writing data is sf. The function equivalent to st_read() regarding data writing is st_write(). There are several types of vector files that can be written: ESRI Shapefile the most common (file extension shp), GPX, KML, GeoJSON and GPKG. See an example, writing a shapefile .shp: # Saving as shapefile st_write(obj = shape_data_join2, dsn = &quot;us_states_unemployment.shp&quot;, delete_dsn = TRUE) # overwrites if it already exists # Or save as GeoJSON (more modern format) st_write(obj = shape_data_join2, dsn = &quot;us_states_unemployment.geojson&quot;, delete_dsn = TRUE) 3.3.3.2 Writing image files To save static maps as images: # Save a ggplot map library(ggplot2) # Create the plot my_map &lt;- ggplot(data = shape_data_join) + geom_sf(aes(fill = unemployment_rate)) + scale_fill_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;) + labs(title = &quot;US Unemployment Rate by State&quot;) + theme_minimal() # Save as PNG ggsave(&quot;us_unemployment_map.png&quot;, plot = my_map, width = 10, height = 8, dpi = 300) # Save as PDF ggsave(&quot;us_unemployment_map.pdf&quot;, plot = my_map, width = 10, height = 8) # Or using base R for a base plot png(&quot;us_unemployment_base.png&quot;, width = 800, height = 600, res = 100) plot(st_geometry(shape_data_join), col = colors[shape_data_join$color_category], main = &quot;Unemployment Rate by State&quot;) dev.off() You can also save interactive leaflet maps as HTML: library(htmlwidgets) library(leaflet) # Create the leaflet map (as shown above) my_leaflet_map &lt;- leaflet(shape_leaflet) %&gt;% addTiles() %&gt;% addPolygons( fillColor = ~pal(unemployment_rate), weight = 1, opacity = 1, color = &quot;white&quot;, fillOpacity = 0.7, popup = ~paste0(&quot;&lt;strong&gt;&quot;, NAME, &quot;&lt;/strong&gt;&lt;br/&gt;&quot;, &quot;Unemployment: &quot;, unemployment_rate, &quot;%&quot;) ) %&gt;% addLegend(pal = pal, values = ~unemployment_rate, title = &quot;Unemployment Rate (%)&quot;) # Save as HTML saveWidget(my_leaflet_map, file = &quot;us_unemployment_interactive.html&quot;) 3.3.4 Section References Lovelace, R.; Nowosad, J.; Muenchow, J. (2019). Geocomputation with R. CRC Press. Available at: https://geocompr.robinlovelace.net/ Pebesma, E. (2018). Simple Features for R: Standardized Support for Spatial Vector Data. The R Journal 10 (1), 439-446, https://doi.org/10.32614/RJ-2018-009. Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. URL https://ggplot2.tidyverse.org Cheng, J., Karambelkar, B., &amp; Xie, Y. (2021). leaflet: Create Interactive Web Maps with Leaflet. R package. URL https://rstudio.github.io/leaflet/ Bivand, R. S., Pebesma, E., &amp; Gomez-Rubio, V. (2013). Applied spatial data analysis with R (Vol. 2, pp. 1-405). New York: Springer. 3.3.5 Exercises Basic Mapping: Explore the us_states dataset from the spData package and identify other available variables (total_pop_15, median_income_15, etc). Create a map showing population density (total_pop_15/AREA) of US states using ggplot2. Add state abbreviations to your map using geom_sf_text(). Interactive Mapping: Create an interactive map using leaflet showing only the Southeast US region. Add popup information showing state name, unemployment rate, and GDP growth. Try changing the base map tiles using addProviderTiles() (hint: try “CartoDB.Positron” or “Esri.WorldImagery”). Data Visualization: Download real unemployment data from the Bureau of Labor Statistics (https://www.bls.gov/data/) and create a map with real data. Create a faceted map showing different regions of the US using facet_wrap() in ggplot2. Florida Focus (UNF special): Create a detailed map focused only on Florida using coordinate limits. Add a marker for Jacksonville and the UNF campus location (30.2672° N, 81.5102° W). Try to find and download Florida county-level shapefiles and create a county map. Save your final map as both a static PNG (using ggsave()) and an interactive HTML file (using saveWidget()). Challenge: Create a small multiples map showing unemployment rates for the four US Census regions separately. Add annotations to highlight interesting patterns (e.g., highest/lowest unemployment states). Customize the color palette to be colorblind-friendly using scale_fill_viridis_c(). "],["m4.html", " 4 Module IV 4.1 String Manipulation in R with stringr 4.2 Regular Expressions (REGEX) 4.3 Reports and Reproducible Research with rmarkdown", " 4 Module IV 4.1 String Manipulation in R with stringr 4.1.1 Introduction The stringr package, as its name suggests, is a package for string manipulation and also for regular expressions. These two techniques are very important in data analysis, because we often deal with text snippets and character columns, where we need to find patterns of words, numbers, emails, phone numbers, names, etc. All content related to the stringr package will be based on the package introduction page, available at http://stringr.tidyverse.org. It will be like a selected and more user-friendly translation of the content provided by the authors. If you want to go deeper into the subject, you can refer to the book R for Data Science by Hadley Wickham. There are four main families of functions in the stringr package: character manipulation: these functions allow us to manipulate individual characters within strings and within vectors; tools for dealing with whitespace, with which we can add, remove and manipulate whitespace; locale-sensitive operations - these operations vary depending on location considering the alphabet used in each country; pattern matching functions - these functions recognize 4 “engines” for describing patterns. The most common are regular expressions, which we will use in this course. 4.1.2 Operations with individual characters 4.1.2.1 Getting and modifying characters # loading library(stringr) To get the length of a string use str_length(): str_length(&quot;abc&quot;) ## [1] 3 To access individual characters (positions) or parts of a string, we can use str_sub(). This function takes as arguments a character vector, a start position and an end position. Both positions can receive a positive integer or a negative integer. If the position passed is a positive integer, the position count is made from left to right (from the beginning of the string) until the desired position is reached. When the position passed as argument is a negative integer, the count is made from right to left (from the end of the string) until the position is reached. In both cases the form of position evaluation is inclusive, that is, it includes the number that was passed. If the positions passed exceed the string limits, the result is truncated without returning any warning. x &lt;- c(&quot;abcdef&quot;, &quot;ghifjk&quot;) # extracting 3rd letter str_sub(x, 3, 3) ## [1] &quot;c&quot; &quot;i&quot; # from second to second-to-last character str_sub(x, 2, -2) ## [1] &quot;bcde&quot; &quot;hifj&quot; str_sub() can also be used to modify strings: str_sub(x, 3, 3) &lt;- &quot;X&quot; x ## [1] &quot;abXdef&quot; &quot;ghXfjk&quot; To duplicate individual strings, use str_dup(): str_dup(x, c(2, 3)) ## [1] &quot;abXdefabXdef&quot; &quot;ghXfjkghXfjkghXfjk&quot; 4.1.2.2 Whitespace The following functions add, remove or modify existing whitespace in strings. str_pad() fills a string with whitespace to a fixed width. Whitespace can be added to the left, right or both sides. This type of function is very useful for generating .fwf type files, i.e. with fixed widths/sizes for columns. x &lt;- c(&quot;abc&quot;, &quot;defghi&quot;) str_pad(x, 10) ## [1] &quot; abc&quot; &quot; defghi&quot; str_pad(x, 10, &quot;right&quot;) ## [1] &quot;abc &quot; &quot;defghi &quot; str_pad(x, 10, &quot;both&quot;) ## [1] &quot; abc &quot; &quot; defghi &quot; We can also fill the string with other elements instead of whitespace: str_pad(x, 10, &quot;both&quot;, pad=&quot;@&quot;) ## [1] &quot;@@@abc@@@@&quot; &quot;@@defghi@@&quot; str_pad() never shortens a string: str_pad(x, 4) ## [1] &quot; abc&quot; &quot;defghi&quot; Note: If you want to ensure that strings have the same size, combine str_pad() with str_trunc(): x &lt;- c(&quot;Short&quot;, &quot;This is a long string&quot;) str_trunc(x, 10) ## [1] &quot;Short&quot; &quot;This is...&quot; str_pad(x, 10) ## [1] &quot; Short&quot; &quot;This is a long string&quot; # x %&gt;% # str_trunc(10) %&gt;% # str_pad(10, &quot;right&quot;) The opposite of str_pad() is str_trim(), which removes leading and trailing spaces: x &lt;- c(&quot; a &quot;, &quot;b &quot;, &quot; c&quot;) str_trim(x) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; str_trim(x, &quot;left&quot;) ## [1] &quot;a &quot; &quot;b &quot; &quot;c&quot; We can use str_wrap() to modify existing whitespace to “wrap” for example a paragraph of text so that the length of each line is as similar as possible. It’s like justifying the paragraph. blah_blah_blah &lt;- str_c( &quot;Roses are red, &quot;, &quot;Violets are blue, &quot;, &quot;... In any combination of words &quot;, &quot; str_wrap gives you a clue &quot; ) # an alternative to c() for strings cat(str_wrap(blah_blah_blah, width = 40)) ## Roses are red, Violets are blue, ... In ## any combination of words str_wrap gives ## you a clue # cat is an alternative to print 4.1.2.3 Locale sensitive A good part of stringr package functions are locale sensitive: they will behave differently depending on the country/region where the user is located. See examples of functions that transform lowercase letters to uppercase and vice versa: x &lt;- &quot;I like horses.&quot; str_to_upper(x) ## [1] &quot;I LIKE HORSES.&quot; str_to_title(x) ## [1] &quot;I Like Horses.&quot; str_to_lower(x) ## [1] &quot;i like horses.&quot; # See the case of Turkish language which has two types of i: one with &quot;dot&quot; and another without str_to_lower(x, &quot;tr&quot;) ## [1] &quot;ı like horses.&quot; Sorting strings and their indices: x &lt;- c(&quot;y&quot;, &quot;i&quot;, &quot;k&quot;) str_order(x) # indices ## [1] 2 3 1 str_sort(x) ## [1] &quot;i&quot; &quot;k&quot; &quot;y&quot; # In Lithuanian language, y is between letters i and k str_sort(x, locale = &quot;lt&quot;) ## [1] &quot;i&quot; &quot;y&quot; &quot;k&quot; An important aspect is that the default stringr configuration always comes with English language to ensure identical behavior in any system when using generic functions. This is different from what normally occurs with base R, where the global locale option normally varies with the regional version of the operating system and generates considerable confusion when developing programs. To get a list of available abbreviations and regions, just run stringi::stri_locale_list(). 4.1.3 Pattern matching The vast majority of stringr functions work with patterns. These functions are parameterized by the type of task they perform and which patterns they match. 4.1.3.1 Tasks Each matching function has the same first two arguments: a vector of strings to process and a pattern to match. The stringr package provides some functions to: detect str_detect(); locate str_locate(); extract str_extract(); match str_match(), replace str_replace(); and split strings str_split(). Let’s see an example with some strings and a Regular Expression to find US phone numbers: strings &lt;- c( &quot;apple&quot;, &quot;212 555 1234&quot;, &quot;212-555-8753&quot;, &quot;Work: 212-555-5835; Home: 646-555-5344&quot; ) phone &lt;- &quot;([0-9]{3})[- .]([0-9]{3})[- .]([0-9]{4})&quot; str_detect() detects the presence or absence of a pattern and returns a logical vector. str_subset() returns the elements of a character vector that match a regular expression. To know which positions of strings contain numbers, we can do: # Which strings contain numbers str_detect(strings, phone) ## [1] FALSE TRUE TRUE TRUE str_subset(strings, phone) ## [1] &quot;212 555 1234&quot; &quot;212-555-8753&quot; ## [3] &quot;Work: 212-555-5835; Home: 646-555-5344&quot; str_count() counts the number of matches. To know how many phone numbers there are in each string, we can do: str_count(strings, phone) ## [1] 0 1 1 2 str_locate() locates the first position of the searched pattern in each string (element) present in the vector and returns a numeric matrix with columns indicating start and end positions. str_locate_all() locates all matches, returning a list of numeric matrices. In which position of each string are the phone numbers located? (loc &lt;- str_locate(strings, phone)) ## start end ## [1,] NA NA ## [2,] 1 12 ## [3,] 1 12 ## [4,] 7 18 str_locate_all(strings, phone) ## [[1]] ## start end ## ## [[2]] ## start end ## [1,] 1 12 ## ## [[3]] ## start end ## [1,] 1 12 ## ## [[4]] ## start end ## [1,] 7 18 ## [2,] 27 38 str_extract() extracts text corresponding to the first match within the string, returning a character vector. str_extract_all() extracts all matches and returns a list of character vectors. str_extract(strings, phone) ## [1] NA &quot;212 555 1234&quot; &quot;212-555-8753&quot; &quot;212-555-5835&quot; str_extract_all(strings, phone) ## [[1]] ## character(0) ## ## [[2]] ## [1] &quot;212 555 1234&quot; ## ## [[3]] ## [1] &quot;212-555-8753&quot; ## ## [[4]] ## [1] &quot;212-555-5835&quot; &quot;646-555-5344&quot; Note that with str_extract_all(), we can identify exactly in which position of the original vector each string was. str_extract_all(strings, phone, simplify = TRUE) ## [,1] [,2] ## [1,] &quot;&quot; &quot;&quot; ## [2,] &quot;212 555 1234&quot; &quot;&quot; ## [3,] &quot;212-555-8753&quot; &quot;&quot; ## [4,] &quot;212-555-5835&quot; &quot;646-555-5344&quot; str_match() extracts capture groups from regular expressions formed by () only for the first match. str_match_all() extracts capture groups from all matches and returns a list of character matrices. # Pull out the three components of the match str_match(strings, phone) ## [,1] [,2] [,3] [,4] ## [1,] NA NA NA NA ## [2,] &quot;212 555 1234&quot; &quot;212&quot; &quot;555&quot; &quot;1234&quot; ## [3,] &quot;212-555-8753&quot; &quot;212&quot; &quot;555&quot; &quot;8753&quot; ## [4,] &quot;212-555-5835&quot; &quot;212&quot; &quot;555&quot; &quot;5835&quot; str_match_all(strings, phone) ## [[1]] ## [,1] [,2] [,3] [,4] ## ## [[2]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;212 555 1234&quot; &quot;212&quot; &quot;555&quot; &quot;1234&quot; ## ## [[3]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;212-555-8753&quot; &quot;212&quot; &quot;555&quot; &quot;8753&quot; ## ## [[4]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;212-555-5835&quot; &quot;212&quot; &quot;555&quot; &quot;5835&quot; ## [2,] &quot;646-555-5344&quot; &quot;646&quot; &quot;555&quot; &quot;5344&quot; str_replace() replaces the first occurrence where there was matching and returns a character vector. str_replace_all() replaces all matches. This is a very interesting function to use when we’re working with identified data and want to hide SSNs, phone numbers, etc. See an example with phone numbers. str_replace(strings, phone, &quot;XXX-XXX-XXXX&quot;) ## [1] &quot;apple&quot; &quot;XXX-XXX-XXXX&quot; ## [3] &quot;XXX-XXX-XXXX&quot; &quot;Work: XXX-XXX-XXXX; Home: 646-555-5344&quot; str_replace_all(strings, phone, &quot;XXX-XXX-XXXX&quot;) ## [1] &quot;apple&quot; &quot;XXX-XXX-XXXX&quot; ## [3] &quot;XXX-XXX-XXXX&quot; &quot;Work: XXX-XXX-XXXX; Home: XXX-XXX-XXXX&quot; str_split_fixed() splits the string into a fixed number of parts based on the pattern passed as argument and returns a character matrix. str_split() separates a string into a variable number of parts and returns a list of character vectors. str_split(&quot;a-b-c&quot;, &quot;-&quot;) ## [[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; str_split_fixed(&quot;a-b-c&quot;, &quot;-&quot;, n = 2) ## [,1] [,2] ## [1,] &quot;a&quot; &quot;b-c&quot; 4.1.3.2 Indices and matching: str_subset() allows extracting elements from a string vector, if it contains the character or group of characters informed. fruit &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;, &quot;pineapple&quot;) str_subset(fruit, &quot;a&quot;) ## [1] &quot;apple&quot; &quot;banana&quot; &quot;pear&quot; &quot;pineapple&quot; str_which() returns the position of the target vector, where a match was found for a certain character or set of characters informed. str_which(LETTERS, &quot;F&quot;) ## [1] 6 # str_which(LETTERS, &quot;F|Y&quot;) 4.1.4 Section References Wickham, H. (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. https://CRAN.R-project.org/package=stringr. ____. (2020). stringr vignette: Introduction. URL http://stringr.tidyverse.org Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: www.r4ds.co.nz 4.2 Regular Expressions (REGEX) 4.2.1 Introduction Programming languages have more than one type of pattern search mechanism in strings. Regular expressions are the most used mechanism. Therefore, it will be our focus in this course. However, know that the stringr package also brings implementations of the other 3 types, which we describe below: Fixed bytewise matching with the fixed() function; Locale-sensitive character matching with coll() (collation search); Text boundary analysis with the boundary() function. If you’re interested in the subject, you can seek more information in the stringr package documentation. But what exactly would Regular Expressions be? Regular Expressions are concise and flexible forms to describe patterns (that we’re searching for) in strings. In this section, we’ll describe the main aspects related to constructing regular expressions. For this we’ll use some of the examples described in the stringr package vignettes. First we’ll make a general introduction about regular expressions and then we’ll see examples using the stringr package. Why are regular expressions important? Regular expressions allow us to describe in more general terms what we want to search in a string. Normally, it’s more efficient to use regular expressions, because if we search for simple characters, we’ll only get the exact match for that character. Have you thought about how we would search only for phone numbers, email addresses, SSNs or EINs in the middle of data (for example web pages) that are not exactly organized in columns? It should be noted that regular expressions is a technique used practically throughout the programming world. It’s not a particularity only of the R language. Regular expressions (regex), in general, are constructed from the combination of 3 components: literal characters: which will only match if there are identical literal characters in the data; character classes: which allow matching by multiple characters - they are composed of characters inside two brackets [ ]; modifiers or anchors: which will operate on characters, classes and combinations of both. 4.2.2 REGEX Examples using stringr 4.2.2.1 Literal matches (basic match/literal characters) The simplest pattern for matching is: x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_extract(x, &quot;an&quot;) ## [1] NA &quot;an&quot; NA We can ignore uppercase and lowercase letters with ignore_case = TRUE: bananas &lt;- c(&quot;banana&quot;, &quot;Banana&quot;, &quot;BANANA&quot;) str_detect(bananas, &quot;banana&quot;) ## [1] TRUE FALSE FALSE str_detect(bananas, regex(&quot;banana&quot;, ignore_case = TRUE)) ## [1] TRUE TRUE TRUE Continuing with the examples, the next step is to know the role played by .. Its function is to search for any character except a newline (\\n): str_extract(x, &quot;.a.&quot;) ## [1] NA &quot;ban&quot; &quot;ear&quot; But if you want to find even characters that indicate a newline, you can “set” dotall = TRUE inside the function responsible for the matching mechanism, which is the regex() function: str_detect(&quot;\\nX\\n&quot;, &quot;.X.&quot;) ## [1] FALSE str_detect(&quot;\\nX\\n&quot;, regex(&quot;.X.&quot;, dotall = TRUE)) ## [1] TRUE 4.2.2.2 Escaping characters If . matches any character, how can we do literal matching of a period “.” in the data? We’ll have to use an escape character to tell R that we want a literal match and not use the special behavior of .. In REGEX, a backslash \\ is used for this purpose. So, to search for a simple “.” in the data, we use \\.. But there’s a catch: the backslash is also treated as a special character in R when it comes to strings. Therefore, we would have to add another backslash forming the string \\\\. in order to match a simple period in the data. dot &lt;- &quot;\\\\.&quot; # But see that as REGEX, there&#39;s only one backslash: \\. writeLines(dot) ## \\. # This tells R to explicitly search for a period str_extract(c(&quot;abc&quot;, &quot;a.c&quot;, &quot;bef&quot;), &quot;a\\\\.c&quot;) ## [1] NA &quot;a.c&quot; NA To help you understand how many backslashes you’ll need to write in the code, let’s think that there are two different mechanisms: the R interpreter and the REGEX mechanism. When you send a regular expression to the interpreter, it will pass through a filter where R rules will be applied. After this first filter, the expression goes to a new instance, where the REGEX mechanism will act. Think of these steps as a toll booth. For each backslash that needs to reach the last toll stage, you also need a backslash \\ to “pay the toll” of the first stage. Backslashes \\ are therefore your currency and you can’t carry more or less “money” than you need. If the expression has to arrive at the REGEX stage as \\., so that the last backslash is seen as a special character that de-characterizes the special functioning of ., thus making a literal match, you need to send one more backslash \\ to be consumed at the R interpreter stage. That’s why, in your code, you should write \\\\.. Have you thought, then, how we would do literal matching of a backslash in a string? Let’s think again as a toll booth, starting from the last stage to the first. In the REGEX mechanism, last toll stage, the expression must arrive with two backslashes \\\\: the left one acting as a special character, which eliminates the special function of the right backslash. Therefore, to carry two backslashes to the end of the process, you need two other backslashes \\\\ to be consumed at the R interpreter stage. Therefore, to do literal matching of a backslash in a string, your code should be written as \\\\\\\\. What happens, in fact, is that the interpreter separates each pair of backslashes, making the left one remove the special functioning of the right backslash in each pair. Thus, only two backslashes arrive at the REGEX mechanism. x &lt;- &quot;a\\\\b&quot; writeLines(x) ## a\\b str_extract(x, &quot;\\\\\\\\&quot;) ## [1] &quot;\\\\&quot; From now on, when we refer to regular expressions, we’ll use the form with only one \\. However, know that in your code in R functions, you should add one more backslash \\\\. 4.2.2.3 Matching multiple characters (classes) First, we’ll see some shortcuts for character classes: shortcuts classes \\w alphanumeric and _ (any word) \\W non-alphanumeric (anything different from words and _) \\d digits \\D non-digits \\s space \\S non-space Let’s move on to examples: str_extract_all(&quot;Don&#39;t eat that!&quot;, &quot;\\\\w+&quot;)[[1]] ## [1] &quot;Don&quot; &quot;t&quot; &quot;eat&quot; &quot;that&quot; str_split(&quot;Don&#39;t eat that!&quot;, &quot;\\\\W&quot;)[[1]] ## [1] &quot;Don&quot; &quot;t&quot; &quot;eat&quot; &quot;that&quot; &quot;&quot; str_extract_all(&quot;1 + 2 = 3&quot;, &quot;\\\\d+&quot;)[[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; (text &lt;- &quot;Text \\t with\\n\\t\\tbad spacing \\f&quot;) ## [1] &quot;Text \\t with\\n\\t\\tbad spacing \\f&quot; str_replace_all(text, &quot;\\\\s+&quot;, &quot; &quot;) ## [1] &quot;Text with bad spacing &quot; Another interesting shortcut is \\b which searches for word boundaries/borders, i.e., transitions between word characters and non-word characters. \\B does the opposite. str_replace_all(&quot;The quick brown fox&quot;, &quot;\\\\b&quot;, &quot;_&quot;) ## [1] &quot;_The_ _quick_ _brown_ _fox_&quot; str_replace_all(&quot;The quick brown fox&quot;, &quot;\\\\B&quot;, &quot;_&quot;) ## [1] &quot;T_h_e q_u_i_c_k b_r_o_w_n f_o_x&quot; You can consult other interesting shortcuts in this stringr package vignette. There’s also the possibility of creating our own classes using []: [abc]: matches a, b or c; [a-z]: matches any lowercase character between a and z; [A-Z]: matches any uppercase character between A and Z; [^abc]: matches anything except a, b, or c; [\\^\\-]: matches ^ or -. Remember to add one more backslash in front of each backslash when passing the command in R There are also several pre-built classes we can use with brackets: [:punct:]: punctuation; [:alpha:]: letters; [:lower:]: lowercase letters; [:upper:]: UPPERCASE LETTERS; [:digit:]: digits; [:alnum:]: letters and numbers. [:cntrl:]: control characters. [:graph:]: letters, numbers and punctuation. [:print:]: letters, numbers, punctuation and whitespace. [:space:]: space characters (equivalent to \\s). [:blank:]: space and tab. These expressions go inside other brackets: y &lt;- c(1234, &quot;R&quot;, &quot;UNF&quot;, &quot; &quot;, &quot;Hello, how are you?&quot;) str_extract_all(y, &quot;[[:digit:]]&quot;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ## ## [[2]] ## character(0) ## ## [[3]] ## character(0) ## ## [[4]] ## character(0) ## ## [[5]] ## character(0) str_extract_all(y, &quot;[[:digit:]a]&quot;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ## ## [[2]] ## character(0) ## ## [[3]] ## character(0) ## ## [[4]] ## character(0) ## ## [[5]] ## [1] &quot;a&quot; str_extract_all(y, &quot;[[:digit:]hw]&quot;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ## ## [[2]] ## character(0) ## ## [[3]] ## character(0) ## ## [[4]] ## character(0) ## ## [[5]] ## [1] &quot;h&quot; &quot;w&quot; str_extract_all(y, &quot;[y[:upper:]w]&quot;) ## [[1]] ## character(0) ## ## [[2]] ## [1] &quot;R&quot; ## ## [[3]] ## [1] &quot;U&quot; &quot;N&quot; &quot;F&quot; ## ## [[4]] ## character(0) ## ## [[5]] ## [1] &quot;H&quot; &quot;w&quot; &quot;y&quot; 4.2.2.4 Alternation Operator | is the alternation operator that allows choosing between one or more possible matches. abc|def will match abc or def. str_detect(c(&quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;), &quot;abc|def&quot;) ## [1] TRUE TRUE FALSE 4.2.2.5 Grouping Parentheses can serve to alter precedence rules or form groups. The same thing we saw in Module 1 to alter precedence rules applies to REGEX: str_extract(c(&quot;grey&quot;, &quot;gray&quot;), &quot;gre|ay&quot;) ## [1] &quot;gre&quot; &quot;ay&quot; str_extract(c(&quot;grey&quot;, &quot;gray&quot;), &quot;gr(e|a)y&quot;) ## [1] &quot;grey&quot; &quot;gray&quot; Parentheses define groups and we can backreference these groups using \\group_number to indicate that groups can repeat more times, as well as the order in which they would repeat in the string. pattern &lt;- &quot;(1|2)(3|4)\\\\1&quot; combinations &lt;- list(&quot;1213&quot;, &quot;1413&quot;, &quot;2324&quot;, &quot;1111&quot;, &quot;2222&quot;, &quot;1415&quot;, &quot;1313&quot;, &quot;1331&quot;) combinations %&gt;% str_subset(pattern) ## [1] &quot;1413&quot; &quot;2324&quot; &quot;1415&quot; &quot;1313&quot; pattern2 &lt;- &quot;(1|2)(3|4)\\\\1\\\\2&quot; combinations %&gt;% str_subset(pattern2) ## [1] &quot;1313&quot; pattern3 &lt;- &quot;(1|2)(3|4)\\\\2\\\\1&quot; combinations %&gt;% str_subset(pattern3) ## [1] &quot;1331&quot; 4.2.2.6 Anchors or modifiers Anchoring means establishing a pattern for the beginning or end of the string we’re searching for. ^ searches for the pattern at the beginning of the string; $ searches for the pattern at the end of the string. x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_extract(x, &quot;^a&quot;) ## [1] &quot;a&quot; NA NA str_extract(x, &quot;a$&quot;) ## [1] NA &quot;a&quot; NA 4.2.2.7 Repetitions We can control how many times a pattern appears in a certain part of the string with: ?: 0 or 1. +: 1 or more. *: 0 or more. x &lt;- &quot;1888 is the longest year in Roman numerals: MDCCCLXXXVIII&quot; str_extract(x, &quot;CC?&quot;) ## [1] &quot;CC&quot; str_extract(x, &quot;CC+&quot;) ## [1] &quot;CCC&quot; str_extract(x, &#39;C[LX]+&#39;) ## [1] &quot;CLXXX&quot; str_match(&quot;banana&quot;, &#39;(na)+&#39;) ## [,1] [,2] ## [1,] &quot;nana&quot; &quot;na&quot; We can specify the exact number of repetitions we expect with: {n}: exactly \\(n\\) times; {n,}: \\(n\\) times or more; {n,m}: between \\(n\\) and \\(m\\) times. str_extract(x, &quot;C{2}&quot;) ## [1] &quot;CC&quot; str_extract(x, &quot;C{2,}&quot;) ## [1] &quot;CCC&quot; str_extract(x, &quot;C{2,3}&quot;) ## [1] &quot;CCC&quot; There are several other patterns and expressions that can be used. Search ??stringi_search-regex or visit the stringr website. 4.2.3 Section References Wickham, H. (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. https://CRAN.R-project.org/package=stringr. ____. (2020). stringr vignette: Introduction. URL http://stringr.tidyverse.org Wickham, H.; Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. december 2016. 522 pages. Available at: www.r4ds.co.nz 4.3 Reports and Reproducible Research with rmarkdown 4.3.1 Introduction We’ve reached a point in the course where we already have powerful tools to analyze and process data. However, nowadays, there’s another stage as important as the previous ones in Data Science: sharing and communicating your analyses. For this purpose, R is certainly the most powerful tool nowadays: you can integrate from the data analysis stage to sharing your codes, graphs and findings through reports, slides, \\(\\TeX\\) articles and even books. This course material itself was all made within the R language. In this section, we’ll focus on report production. We’ll also see how to make these reports adapt automatically to changes in the data that originate your analysis. In addition to this practical issue, all data and codes used in an analysis can be shared with your team, which reinforces the reproducibility character of the R language. Anyone else can easily replicate and verify/validate the results obtained by you. The tool that allows us to do most of these things we mentioned above is the rmarkdown package. It’s a package that gravitates around the tidyverse core. rmarkdown unites text writing and code writing in a single place, through markdown markup language. The markup language has a quite simple syntax that makes text production very agile, unlike what occurs with \\(HTML\\) and \\(\\LaTeX\\), for example. This means you don’t need to leave RStudio or even switch windows or tabs to include text, figures, outputs or code chunks in an R Markdown document. The rmarkdown package is so surprising that from it emerged derivative packages that allow creating websites and blogs with blogdown and making books and course materials like this one you’re reading through the bookdown package, among others. To start making a report in R Markdown, you need to create a new .Rmd file. Click on , as you normally do to create a script, only this time select “R Markdown” . A new window will open in RStudio, where you should choose what type of output file you want, whether HTML, PDF or .docx, as well as its name and your report title. Let’s choose PDF. Note that a new tab is automatically created in RStudio, with a pre-formatted .Rmd report template. ATTENTION: If this is your first time using R Markdown on Windows, RStudio itself will offer to install some necessary packages (and their dependencies) to run rmarkdown. Among them will be the tinytex package. This is a package that performs the minimal installation of \\(\\LaTeX\\) libraries necessary for generating .pdf documents from R Markdown. After installing the packages, just run the code below in the console and then restart your RStudio session. tinytex::install_tinytex() In the created tab, there’s all the data you informed previously and also a series of automatically created examples depicting the functioning of a simple R Markdown report. Note that all text is editable. Documents are generated using the knitr package. This package functions as a support package for rmarkdown, but you don’t need to know it in depth. Knit in English means to knit or unite. And that’s exactly what it does, it stitches and unites all elements that you come to build or program with R Markdown. If you already want to generate a report from the example presented to you when creating a new .Rmd file, you can do so by clicking the Knit button in the RStudio window. After choosing a name and saving your .Rmd file, if you chose the PDF option, you’ll have a .pdf extension file. Test changing the destination files: .html and .docx directly in the Knit button. TIP: For each new command you learn throughout this section, we suggest generating a new report, so you can follow the modifications made in the document. Therefore, we also suggest you delete all content from the suggestion report created when opening a new .Rmd document, keeping only the header data: title, author, date and output. 4.3.2 Header In the header you can specify all technical aspects of your text formatting in R Markdown. There are several options, but we’ll focus on the most basic ones that appear on the screen at this moment. title contains your document title; author your name; date the document generation date; output the type of document to be generated, whether HTML, PDF or Word. Some useful tricks: If you want to add a co-author, use: author: - Author1 Name - Author2 Name To add a subtitle, just write: title: &quot;Your Title&quot; subtitle: &quot;Subtitle for the report&quot; So you don’t have to manually change the date every time you run Knit, use the format() function together with Sys.time(). Note that this code is passed between backticks ``. date: &quot;`r format(Sys.time(), &#39;%B %d, %Y&#39;)`&quot; 4.3.3 Text Formatting R Markdown’s text formatting syntax is very simple. That’s why text production with it is very fast. This comes at the cost of not having as much flexibility in altering textual elements as in a language like \\(\\LaTeX\\), but still, the formatting possibilities are quite considerable. 4.3.3.1 Titles The # symbol is used to define titles. For each # added, you descend one hierarchy and create a subtitle of the previous title. The fewer # there are before your title, the greater the hierarchy and consequently the larger the font. # Article Title ## Subtitle ### Section #### Subsection 4.3.3.2 Paragraphs To write a paragraph just start writing any text. To add paragraphs just skip a line, leaving a blank space between paragraphs This is the first paragraph of your text. You can write normally and it will appear in your report. After skipping a line, you start a new paragraph. Add the ideas you want in this second paragraph 4.3.3.3 Font formatting You can apply italic and bold formatting to specific words, expressions or complete excerpts of your text, placing the word or excerpt in question between asterisks. For bold formatting, use **word or excerpt**: word or excerpt. For italic formatting, use *word or excerpt*: word or excerpt. You can get the same effect using underscore instead of asterisks, as in these examples _word or excerpt_: word or excerpt; and __word or excerpt__: word or excerpt. 4.3.3.4 Footnotes Footnotes can be inserted in the text using the scheme word^[Text that will go to the footnote about the word.] In this text we&#39;re going to insert a footnote about the word Statistics^[Statistics is the discipline that consists of collecting, organizing, analyzing and presenting data.] 4.3.3.5 Making lists and item enumeration 4.3.3.5.1 Unnumbered lists To create unnumbered lists, we can use either * or -: * item X * item Y * item Z item X item Y item Z - item X - item Y - item Z item X item Y item Z In unnumbered lists, to create subitems, you must give 4 spaces or TAB from the left margin and use - or +: * item X - subitem * item Y - subitem + subsubitem * item Z + subitem + subitem item X subitem item Y subitem subsubitem item Z subitem subitem 4.3.3.5.2 Numbered lists To create numbered lists, we use the numeral accompanied by a period: 1., 2., 3. and so on. For creating subitems, in case of numbered lists, use two TAB or 4 spaces followed by -. 1. item A - subitem 2. item B - subitem - subitem 2. item C - subitem - subitem item A subitem item B subitem subitem item C subitem subitem 4.3.3.6 Tables Tables can be added using | to separate columns and ------ to separate the header, containing column names. Note that the straight bars that separate columns must be aligned. column1 | column2 | column3 --------|----------|-------- Name1 | Address1 | Value1 Name2 | Address2 | Value2 Name3 | Address3 | Value3 column1 column2 column3 Name1 Address1 Value1 Name2 Address2 Value2 Name3 Address3 Value3 4.3.4 Inserting external figures You can include in your report external figures, that is, figures that are not generated from R. You can reference both figures that are stored locally on your machine and figures available on the web. ![Web Figure Description](https://www.r-project.org/Rlogo.png) ![Logo of one of my packages](./fig/mRpostman_logo.png) Web Figure Description Logo of one of my packages 4.3.5 Inserting links The process of inserting links follows a very similar approach to inserting external figures. The difference is that you won’t need ! anymore. Also, only the text inside brackets [] will appear to the reader. When clicked, they will be directed to the link to be passed inside parentheses (). Click on this [LINK](https://www.unf.edu). File available at [https://www.unf.edu](https://www.unf.edu). Click on this LINK. File available at https://www.unf.edu. 4.3.6 Mathematical formulas You can insert mathematical formulas using \\(\\LaTeX\\) principles. See the probability density function of a Normal distribution. For this, you must pass the formula between double $$. Note how elegant the formatting is. $$ f(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 } $$ \\[ f(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 } \\] If you want to present some formula in the middle of a paragraph text, pass the formula only between two simple $: The probability density function of the Normal Distribution is given by $f(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 }$. The probability density function of the Normal Distribution is given by \\(f(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 }\\). 4.3.7 Code insertion and execution The biggest advantage of R Markdown is probably the possibility of joining code, outputs and text all in the same place in a very simple and natural way. 4.3.7.1 Simple insertion To present your code along a line, without necessarily executing it, use simple backticks. In R, we can create a numeric vector x through the code `x &lt;- c(1:10)`. In R, we can create a numeric vector x through the code x &lt;- c(1:10). If we need to present a larger piece of code, we can do it between triple backticks ```, forming a block: This is a larger piece of code: ``` x &lt;- c(1:10) sum(x) ``` Which results in: This is a larger piece of code: x &lt;- c(1:10) sum(x) 4.3.7.2 Insertions with execution and other controls To start presenting your codes together with respective outputs (which include graphs), we use what we call chunks, which are nothing more than pieces of code to be executed during document processing. rmarkdown and its interaction with RStudio are so sophisticated that, if you have other languages installed on your machine, you can even change the R language display format to Python for example. However, our focus will be only on configuring the most used parameters. Initially, to create an R code chunk, you must use the same triple backticks ``` from the previous example, accompanied by the notation {r}. Don’t forget to close the chunk with the same triple quotes. ```{r} x &lt;- 1:10 sum(x) ``` As a result, we now have the printing of the output of the previous code: x &lt;- 1:10 sum(x) ## [1] 55 TIP: It’s also possible to execute code snippets inline, in the middle of paragraphs. For this, we use `r sum(x)` For example: The sum of vector x is `r sum(x)`. Which results in: The sum of vector x is 55. 4.3.7.2.1 Main chunk options The main chunk options are: results: specifies how, and if, chunk results will be shown; options: markup (default): displays results normally hide: doesn’t display outputs in final report hold: displays results only at end of report asis: doesn’t reformat results, displaying (useful when outputs are HTML code, for example) echo: specifies if chunk code will be displayed options: TRUE (default): displays codes above output FALSE: displays only output generated by chunk eval: specifies if chunk will be executed or not options: TRUE (default): executes chunk FALSE: doesn’t execute chunk (useful when we want to display only codes and not their output) message and warning: defines if messages and other warnings generated during code execution options: TRUE (default): displays messages and warnings generated during chunk execution FALSE: suppresses display of messages and warnings (useful to suppress package loading messages) fig.cap: specifies a description for figure generated in chunk fig.align: defines alignment of figure generated in chunk options: center (default): alignment at document center left: left alignment right: right alignment fig.height and fig.width: defines figure height and width in inches - default is size 7 If nothing is specified for a certain option, default configurations are used in code evaluation and results display. These options must be passed in chunk headers, next to the letter r and inside braces {}, for example: ```{r, echo=FALSE, message=FALSE} library(dplyr) x &lt;- 1:10 x %&gt;% sum() ``` You can also assign names to your chunks. This is highly recommended when producing relatively large reports with several chunks, as it will facilitate identification of eventual errors during document generation process. Names must be informed before the first comma, at a space distance from letter r: {r chunk_name, options} Let’s see some examples, where we create some named chunks, to read one of the databases from previous modules and plot a graph using ggplot2: ```{r loading, message=FALSE} library(readr) library(dplyr) library(nycflights13) # Loading flights data flights_data &lt;- flights # Creating summary by carrier carrier_summary &lt;- flights_data %&gt;% group_by(carrier) %&gt;% summarise( total_flights = n(), avg_delay = mean(dep_delay, na.rm = TRUE), avg_distance = mean(distance, na.rm = TRUE) ) %&gt;% arrange(desc(total_flights)) ``` ```{r plot, fig.cap=&quot;Source: nycflights13 package&quot;, fig.height=5, fig.width=7, fig.align=&quot;center&quot;} library(ggplot2) carrier_summary %&gt;% ggplot(aes(x = reorder(carrier, -total_flights), y = total_flights)) + geom_col(fill = &quot;steelblue&quot;) + labs(title = &quot;Total Flights by Carrier&quot;, x = &quot;Carrier&quot;, y = &quot;Number of Flights&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ``` Which would result in: library(readr) library(dplyr) library(nycflights13) # Loading flights data flights_data &lt;- flights # Creating summary by carrier carrier_summary &lt;- flights_data %&gt;% group_by(carrier) %&gt;% summarise( total_flights = n(), avg_delay = mean(dep_delay, na.rm = TRUE), avg_distance = mean(distance, na.rm = TRUE) ) %&gt;% arrange(desc(total_flights)) library(ggplot2) carrier_summary %&gt;% ggplot(aes(x = reorder(carrier, -total_flights), y = total_flights)) + geom_col(fill = &quot;steelblue&quot;) + labs(title = &quot;Total Flights by Carrier&quot;, x = &quot;Carrier&quot;, y = &quot;Number of Flights&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Figure 4.1: Source: nycflights13 package 4.3.8 More sophisticated tables When we use a tibble or data frame and the destination output is an HTML file, we benefit from the fact that R Markdown recognizes the format and prints the tibble or data frame content as an R Markdown table. For this just include the following lines in the YAML header, changing to paged, kable or tibble. Let’s see an example with paged --- title: &quot;Title&quot; output: html_document: df_print: &lt;option&gt; --- Let’s use the df_print: paged option, which will make the table printed in a paginated way, displaying only a few lines (and columns) at a time and allowing users to navigate through its content interactively. After changing the header, just call the carrier_summary object from within a chunk. ```{r table, cols.print = 5, rows.print = 5} carrier_summary ``` Note that the cols.print and rows.print arguments control the number of columns and rows to be displayed in each pagination. The result will be the following: TIP: If you want to better control table outputs, or seek to generate more sophisticated tables in PDF or Word reports, we can use the knitr::kable function inside an R Markdown chunk. knitr::kable(carrier_summary[1:5, 1:4], format = &quot;latex&quot;) In the code above, we present an extract of data (first 5 rows and first 4 columns) from the data frame named carrier_summary that we used throughout the course. The format = latex option is suitable for producing tables in \\(\\LaTeX\\) style. If the goal is to make the table look even better you can use the booktabs = TRUE option, which makes the pandoc engine use the \\(\\LaTeX\\) booktabs package to generate the table. There are several other options to further improve table style, such as adding footnotes, titles, colors, etc. For this you should investigate other options of the kable function itself and the kableExtra package that expands customization possibilities. 4.3.9 Section References Allaire, J. J.; Xie, Y.; McPherson, J.; Luraschi, J.; Ushey, K.; Atkins, A.; Wickham, H.; Cheng, J.; Chang, W.; Iannone, R. (2019). rmarkdown: Dynamic Documents for R. R package version 1.13. URL https://rmarkdown.rstudio.com. Xie, Y. (2019). R Markdown Cookbook. CRS Press. Available at: https://bookdown.org/yihui/rmarkdown-cookbook/ Xie Y.; Allaire, J. J.; Grolemund, G. (2018). R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. Available at: https://bookdown.org/yihui/rmarkdown. R MARKDOWN REFERENCE GUIDE. Available at: https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf. 4.3.10 Exercises Choose a report you worked on recently and try to reproduce all of it or just a section using R Markdown knowledge. Give preference to works that involve data that allow applying most of the techniques seen throughout the course. Create a simple R Markdown report about a topic of your choice (could be about Jacksonville, UNF, your major, etc.) that includes: At least 3 different heading levels Bold and italic text A numbered list and an unnumbered list A table An external image or link A mathematical formula At least 2 code chunks with different options Practice with the nycflights13 dataset: Create an R Markdown document that analyzes flight delays Include at least one table and one plot Use inline R code to report summary statistics Export to both HTML and PDF formats "],["conclusion.html", "Conclusion", " Conclusion Although the course is introductory, I believe you were able to reach a level of fluency in R that will have a significant impact on your work. We covered basic topics on how the language works, its main objects, tools for data analysis, and moved on to the topic of reproducibility in R. Along the way, you engaged with excellent packages and techniques that will greatly facilitate your data-analysis work. From now on, you are ready to move forward more independently in developing data analysis solutions using R. Your level of proficiency now allows you to think more clearly about how to organize your data, what kind of problem you have, the best way to approach it, and—most importantly—how and where to seek help to solve it. Make the most of the excellent materials you have at hand, and return to them and to the references whenever needed. Thank you for being part of this journey! Allan Quadros "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
